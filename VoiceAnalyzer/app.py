import sys
import os
from pathlib import Path
from PySide6.QtWidgets import (
    QApplication, QWidget, QPushButton, QVBoxLayout, QLabel, QFileDialog,
    QTextEdit, QScrollArea, QProgressBar, QMessageBox, QDialog, QComboBox,
    QDialogButtonBox, QFormLayout, QHBoxLayout, QTabWidget, QListWidget, 
    QListWidgetItem, QCheckBox
)
from PySide6.QtCore import Qt, QThread, Signal
from PySide6.QtGui import QColor
import subprocess
import json
import collections
import webbrowser
import tempfile
import time
import requests
from tqdm import tqdm
import zipfile
import shutil

# Whisper Ùˆ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†
import whisper

# ØªØµØ­ÛŒØ­ Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ§Ø±Ø³ÛŒ
try:
    from persiantools import digits
    from persiantools import characters
    PERSIAN_TOOLS_AVAILABLE = True
except ImportError:
    PERSIAN_TOOLS_AVAILABLE = False
    print("Warning: persiantools not installed. Install with: pip install persiantools")


# Google Speech-to-Text
try:
    from google.cloud import speech
    GOOGLE_SPEECH_AVAILABLE = True
except ImportError:
    GOOGLE_SPEECH_AVAILABLE = False
    print("Warning: google-cloud-speech not installed. Install with: pip install google-cloud-speech")

# Vosk Speech Recognition
try:
    import vosk
    import json
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False
    print("Warning: vosk not installed. Install with: pip install vosk")

# Microsoft Azure Speech
try:
    import azure.cognitiveservices.speech as speechsdk
    AZURE_SPEECH_AVAILABLE = True
except ImportError:
    AZURE_SPEECH_AVAILABLE = False
    print("Warning: azure-cognitiveservices-speech not installed. Install with: pip install azure-cognitiveservices-speech")

# AssemblyAI
try:
    import assemblyai as aai
    ASSEMBLYAI_AVAILABLE = True
except ImportError:
    ASSEMBLYAI_AVAILABLE = False
    print("Warning: assemblyai not installed. Install with: pip install assemblyai")

# Hugging Face Transformers
try:
    from transformers import pipeline, AutoModelForCTC, AutoProcessor
    import torch
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False
    print("Warning: transformers not installed. Install with: pip install transformers torch")

# SpeechRecognition
try:
    import speech_recognition as sr
    SPEECHRECOGNITION_AVAILABLE = True
except ImportError:
    SPEECHRECOGNITION_AVAILABLE = False
    print("Warning: SpeechRecognition not installed. Install with: pip install SpeechRecognition")

# Silero STT
try:
    import torch
    import torchaudio
    import torch.hub
    import omegaconf
    SILERO_AVAILABLE = True
except ImportError as e:
    SILERO_AVAILABLE = False
    print(f"Warning: Silero STT dependencies not available: {e}")
    print("To install Silero STT dependencies:")
    print("1. First install omegaconf: pip install omegaconf")
    print("2. Then install PyTorch:")
    print("   For CPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu")
    print("   For GPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118")

# Kaldi
try:
    import kaldi_io
    KALDI_AVAILABLE = True
except ImportError:
    KALDI_AVAILABLE = False
    print("Warning: kaldi-io not installed. Install with: pip install kaldi-io")

# Ø¨Ø±Ø±Ø³ÛŒ ffmpeg Ø¯Ø± PATH
try:
    subprocess.run(["ffmpeg", "-version"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
except FileNotFoundError:
    raise RuntimeError("FFmpeg not found in PATH! Install it or add to PATH.")

# Ù…Ø³ÛŒØ± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ø³ØªÙˆÙ…
CUSTOM_DICT_FILE = Path("custom_dict.json")
if not CUSTOM_DICT_FILE.exists():
    with open(CUSTOM_DICT_FILE, "w", encoding="utf-8") as f:
        json.dump({}, f, ensure_ascii=False, indent=2)

# Ù…Ø³ÛŒØ± ØªÚ©ÛŒÙ‡ Ú©Ù„Ø§Ù…â€ŒÙ‡Ø§
RELYING_DICT_FILE = Path("relying_dict.json")
if not RELYING_DICT_FILE.exists():
    with open(RELYING_DICT_FILE, "w", encoding="utf-8") as f:
        json.dump({"ØªÚ©ÛŒÙ‡_Ú©Ù„Ø§Ù…": ["Ø®Ø¨", "Ø¢Ø®Ù‡", "ÛŒØ¹Ù†ÛŒ", "Ø­Ø§Ù„Ø§"]}, f, ensure_ascii=False, indent=2)

# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
CONFIG_FILE = Path("voice_analyzer_config.json")
if not CONFIG_FILE.exists():
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump({
            "selected_model": "vosk_persian",
            "last_audio_path": "",
            "window_geometry": None,
            "preferred_language": "fa"
        }, f, ensure_ascii=False, indent=2)

# Import Ù¾Ù†Ø¬Ø±Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
from custom_dict_manager import DictManager


class ConfigManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ù†Ø§Ù…Ù‡"""
    
    @staticmethod
    def load_config():
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ§ÛŒÙ„"""
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {e}")
            return {
                "selected_model": "vosk_persian",
                "last_audio_path": "",
                "window_geometry": None,
                "preferred_language": "fa"
            }
    
    @staticmethod
    def save_config(config):
        """Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø± ÙØ§ÛŒÙ„"""
        try:
            with open(CONFIG_FILE, "w", encoding="utf-8") as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {e}")
            return False
    
    @staticmethod
    def update_model(model_name):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡"""
        config = ConfigManager.load_config()
        config["selected_model"] = model_name
        return ConfigManager.save_config(config)
    
    @staticmethod
    def update_audio_path(audio_path):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…Ø³ÛŒØ± Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ"""
        config = ConfigManager.load_config()
        config["last_audio_path"] = audio_path
        return ConfigManager.save_config(config)
    
    @staticmethod
    def update_window_geometry(geometry):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾Ù†Ø¬Ø±Ù‡"""
        config = ConfigManager.load_config()
        config["window_geometry"] = geometry
        return ConfigManager.save_config(config)

class ModelDownloader:
    """Ú©Ù„Ø§Ø³ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯
    DOWNLOADABLE_MODELS = {
        # Vosk Models (ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
        "vosk_persian": {
            "url": "https://alphacephei.com/vosk/models/vosk-model-fa-0.5.zip",
            "name": "vosk-model-fa-0.5", 
            "size": "1.13 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ",
            "type": "Vosk"
        },
        "vosk_small": {
            "url": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
            "name": "vosk-model-small-en-us-0.15",
            "size": "40 MB",
            "language": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "warning": "âš ï¸ ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "type": "Vosk"
        },
        "vosk_large": {
            "url": "https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip", 
            "name": "vosk-model-en-us-0.22",
            "size": "1.8 GB",
            "language": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "warning": "âš ï¸ ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "type": "Vosk"
        },
        
        # Whisper Models
        "whisper_tiny": {
            "url": "whisper://tiny",
            "name": "whisper-tiny",
            "size": "75 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âš ï¸ Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ",
            "type": "Whisper"
        },
        "whisper_base": {
            "url": "whisper://base",
            "name": "whisper-base",
            "size": "142 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âš ï¸ Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ",
            "type": "Whisper"
        },
        "whisper_small": {
            "url": "whisper://small",
            "name": "whisper-small",
            "size": "466 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨",
            "type": "Whisper"
        },
        "whisper_medium": {
            "url": "whisper://medium",
            "name": "whisper-medium",
            "size": "1.5 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§",
            "type": "Whisper"
        },
        "whisper_large": {
            "url": "whisper://large",
            "name": "whisper-large",
            "size": "3.1 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¯Ù‚Øª",
            "type": "Whisper"
        },
        "whisper_large_v2": {
            "url": "whisper://large-v2",
            "name": "whisper-large-v2",
            "size": "3.1 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡",
            "type": "Whisper"
        },
        "whisper_large_v3": {
            "url": "whisper://large-v3",
            "name": "whisper-large-v3",
            "size": "3.1 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡",
            "type": "Whisper"
        },
        
        # Hugging Face Transformers
        "hf_wav2vec2_persian": {
            "url": "huggingface://m3hrdadfi/wav2vec2-large-xlsr-persian",
            "name": "Wav2Vec2-Large-XLSR-53-Persian",
            "size": "1.2 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ - Hugging Face",
            "type": "HuggingFace"
        },
        "hf_wav2vec2_persian_v3": {
            "url": "huggingface://m3hrdadfi/wav2vec2-large-xlsr-persian-v3",
            "name": "Wav2Vec2-Large-XLSR-53-Persian-V3",
            "size": "1.2 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡ - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª ÙØ§Ø±Ø³ÛŒ (WER: 10.36%)",
            "type": "HuggingFace"
        },
        "hf_wav2vec2_persian_jonatas": {
            "url": "huggingface://jonatasgrosman/wav2vec2-large-xlsr-53-persian",
            "name": "Wav2Vec2-Large-XLSR-53-Persian-Jonatas",
            "size": "1.2 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ - Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ (WER: 30.12%)",
            "type": "HuggingFace"
        },
        "hf_whisper_large_v3_persian": {
            "url": "huggingface://nezamisafa/whisper-large-v3-persian",
            "name": "Whisper-Large-V3-Persian",
            "size": "3.1 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª",
            "type": "HuggingFace"
        },
        "hf_whisper_large_v3_persian_alt": {
            "url": "huggingface://MohammadKhosravi/whisper-large-v3-Persian",
            "name": "Whisper-Large-V3-Persian-Alt",
            "size": "3.1 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ - Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†",
            "type": "HuggingFace"
        },
        "hf_whisper_large_persian_steja": {
            "url": "huggingface://steja/whisper-large-persian",
            "name": "Whisper-Large-Persian-Steja",
            "size": "3.1 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ - Steja (WER: 26.37%)",
            "type": "HuggingFace"
        },
        "hf_wav2vec2_persian_alt": {
            "url": "huggingface://facebook/wav2vec2-large-xlsr-53",
            "name": "Wav2Vec2-Large-XLSR-53-Multilingual",
            "size": "1.2 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âš ï¸ Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡ - Ù†ÛŒØ§Ø² Ø¨Ù‡ fine-tuning Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ",
            "type": "HuggingFace"
        },
        "hf_whisper_tiny": {
            "url": "huggingface://openai/whisper-tiny",
            "name": "Whisper-Tiny-HF",
            "size": "75 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âš ï¸ Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ",
            "type": "HuggingFace"
        },
        "hf_whisper_base": {
            "url": "huggingface://openai/whisper-base",
            "name": "Whisper-Base-HF",
            "size": "142 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âš ï¸ Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ",
            "type": "HuggingFace"
        },
        "hf_whisper_small": {
            "url": "huggingface://openai/whisper-small",
            "name": "Whisper-Small-HF",
            "size": "466 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨",
            "type": "HuggingFace"
        },
        "hf_whisper_medium": {
            "url": "huggingface://openai/whisper-medium",
            "name": "Whisper-Medium-HF",
            "size": "1.5 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§",
            "type": "HuggingFace"
        },
        "hf_whisper_large": {
            "url": "huggingface://openai/whisper-large-v2",
            "name": "Whisper-Large-V2-HF",
            "size": "3.1 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¯Ù‚Øª",
            "type": "HuggingFace"
        },
        "hf_whisper_large_v2": {
            "url": "huggingface://openai/whisper-large-v2",
            "name": "Whisper-Large-V2-HF",
            "size": "3.1 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡",
            "type": "HuggingFace"
        },
        "hf_whisper_large_v3": {
            "url": "huggingface://openai/whisper-large-v3",
            "name": "Whisper-Large-V3-HF",
            "size": "3.1 GB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡",
            "type": "HuggingFace"
        },
        
        # SpeechRecognition
        "speechrecognition_google": {
            "url": "speechrecognition://google",
            "name": "Google Speech Recognition",
            "size": "0 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "ğŸŒ Ø¢Ù†Ù„Ø§ÛŒÙ† - Ø±Ø§ÛŒÚ¯Ø§Ù† 60Ø¯Ù‚ÛŒÙ‚Ù‡/Ù…Ø§Ù‡",
            "type": "SpeechRecognition"
        },
        "speechrecognition_sphinx": {
            "url": "speechrecognition://sphinx",
            "name": "CMU Sphinx",
            "size": "100 MB",
            "language": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "warning": "âš ï¸ ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "type": "SpeechRecognition"
        },
        "speechrecognition_wit": {
            "url": "speechrecognition://wit",
            "name": "Wit.ai",
            "size": "0 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "ğŸŒ Ø¢Ù†Ù„Ø§ÛŒÙ† - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ",
            "type": "SpeechRecognition"
        },
        "speechrecognition_azure": {
            "url": "speechrecognition://azure",
            "name": "Azure Speech",
            "size": "0 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "ğŸŒ Ø¢Ù†Ù„Ø§ÛŒÙ† - Ø±Ø§ÛŒÚ¯Ø§Ù† 5Ø³Ø§Ø¹Øª/Ù…Ø§Ù‡",
            "type": "SpeechRecognition"
        },
        "speechrecognition_bing": {
            "url": "speechrecognition://bing",
            "name": "Bing Speech",
            "size": "0 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "ğŸŒ Ø¢Ù†Ù„Ø§ÛŒÙ† - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ",
            "type": "SpeechRecognition"
        },
        "speechrecognition_houndify": {
            "url": "speechrecognition://houndify",
            "name": "Houndify",
            "size": "0 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "ğŸŒ Ø¢Ù†Ù„Ø§ÛŒÙ† - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ",
            "type": "SpeechRecognition"
        },
        "speechrecognition_ibm": {
            "url": "speechrecognition://ibm",
            "name": "IBM Speech to Text",
            "size": "0 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "ğŸŒ Ø¢Ù†Ù„Ø§ÛŒÙ† - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ",
            "type": "SpeechRecognition"
        },
        
        # Silero STT
        "silero_stt_en": {
            "url": "silero://stt_en",
            "name": "Silero STT English",
            "size": "50 MB",
            "language": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "warning": "âš ï¸ ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "type": "Silero"
        },
        "silero_stt_multilingual": {
            "url": "silero://stt_multilingual",
            "name": "Silero STT Multilingual",
            "size": "200 MB",
            "language": "Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡",
            "warning": "âœ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ÙØ§Ø±Ø³ÛŒ",
            "type": "Silero"
        },
        
        
    }
    
    # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ
    VOSK_MODELS = {
        key: value for key, value in DOWNLOADABLE_MODELS.items() 
        if value["type"] == "Vosk"
    }
    
    @staticmethod
    def download_model(model_id, progress_callback=None):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù†ÙˆØªÛŒÙÛŒÚ©ÛŒØ´Ù† Ø³Ø§Ø¯Ù‡"""
        if model_id not in ModelDownloader.DOWNLOADABLE_MODELS:
            return False, f"Ù…Ø¯Ù„ {model_id} Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯"
        
        model_info = ModelDownloader.DOWNLOADABLE_MODELS[model_id]
        
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper
        if model_info["type"] == "Whisper":
            return ModelDownloader._download_whisper_model(model_id, model_info, progress_callback)
        
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk
        elif model_info["type"] == "Vosk":
            return ModelDownloader._download_vosk_model(model_id, model_info, progress_callback)
        
        return False, f"Ù†ÙˆØ¹ Ù…Ø¯Ù„ {model_info['type']} Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯"
    
    @staticmethod
    def _download_whisper_model(model_id, model_info, progress_callback=None):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Whisper Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù†ÙˆØªÛŒÙÛŒÚ©ÛŒØ´Ù† Ø³Ø§Ø¯Ù‡"""
        try:
            if progress_callback:
                progress_callback(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_info['name']} ({model_info['size']})...")
            
            # Whisper Ø®ÙˆØ¯Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
            model_name = model_id.replace("whisper_", "")
            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Whisper
            if model_name == "large_v2":
                model_name = "large-v2"
            elif model_name == "large_v3":
                model_name = "large-v3"
            
            if progress_callback:
                progress_callback(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Whisper {model_name}...")
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
            model = whisper.load_model(model_name)
            
            if progress_callback:
                progress_callback(f"Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯")
            
            return True, f"Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯"
            
        except Exception as e:
            return False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Whisper: {str(e)}"
    
    @staticmethod
    def _download_vosk_model(model_id, model_info, progress_callback=None):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Vosk Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù†ÙˆØªÛŒÙÛŒÚ©ÛŒØ´Ù† Ø³Ø§Ø¯Ù‡"""
        models_dir = Path.home() / ".vosk" / "models"
        models_dir.mkdir(parents=True, exist_ok=True)
        
        model_path = models_dir / model_info["name"]
        
        # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
        if model_path.exists():
            return True, str(model_path)
        
        try:
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            if progress_callback:
                progress_callback(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_info['name']} ({model_info['size']})...")
            
            response = requests.get(model_info["url"], stream=True)
            response.raise_for_status()
            
            # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
            zip_path = models_dir / f"{model_info['name']}.zip"
            
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„
            if progress_callback:
                progress_callback("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¯Ù„...")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(models_dir)
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ zip
            zip_path.unlink()
            
            return True, str(model_path)
            
        except Exception as e:
            return False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {str(e)}"
    
    @staticmethod
    def is_model_downloaded(model_id):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„"""
        if model_id not in ModelDownloader.DOWNLOADABLE_MODELS:
            return False
        
        model_info = ModelDownloader.DOWNLOADABLE_MODELS[model_id]
        
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper
        if model_info["type"] == "Whisper":
            try:
                model_name = model_id.replace("whisper_", "")
                # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Whisper
                if model_name == "large_v2":
                    model_name = "large-v2"
                elif model_name == "large_v3":
                    model_name = "large-v3"
                
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„ Ø¯Ø± cache Whisper
                import whisper
                import os
                
                # Ù…Ø³ÛŒØ± cache Whisper
                cache_dir = os.path.expanduser("~/.cache/whisper")
                model_file = f"{model_name}.pt"
                model_path = os.path.join(cache_dir, model_file)
                
                return os.path.exists(model_path)
            except:
                return False
        
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk
        elif model_info["type"] == "Vosk":
            models_dir = Path.home() / ".vosk" / "models"
            model_path = models_dir / model_info["name"]
            return model_path.exists()
        
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face - Ø¨Ø±Ø±Ø³ÛŒ cache Ù…Ø­Ù„ÛŒ
        elif model_info["type"] == "HuggingFace":
            try:
                import os
                from transformers import AutoModel, AutoTokenizer
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø² URL
                model_url = model_info["url"]
                if model_url.startswith("huggingface://"):
                    model_name = model_url.replace("huggingface://", "")
                    
                    # Ø¨Ø±Ø±Ø³ÛŒ cache Ù…Ø­Ù„ÛŒ Hugging Face
                    cache_dir = os.path.expanduser("~/.cache/huggingface/hub")
                    
                    # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÙÙˆÙ„Ø¯Ø±Ù‡Ø§ÛŒ cache
                    if os.path.exists(cache_dir):
                        for item in os.listdir(cache_dir):
                            if model_name.replace("/", "--") in item:
                                return True
                    
                    # Ø¨Ø±Ø±Ø³ÛŒ cache transformers
                    try:
                        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ù†Ù„ÙˆØ¯
                        AutoTokenizer.from_pretrained(model_name, local_files_only=True)
                        return True
                    except:
                        return False
                
                return False
            except:
                return False
        
        return False

class ModelDownloadDialog(QDialog):
    """Ø¯ÛŒØ§Ù„ÙˆÚ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
    
    def __init__(self, model_id, model_info, parent=None):
        super().__init__(parent)
        self.model_id = model_id
        self.model_info = model_info
        self.download_thread = None
        self.setup_ui()
        
    def setup_ui(self):
        self.setWindowTitle(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ {self.model_info['name']}")
        self.setModal(True)
        self.resize(400, 200)
        
        self.setStyleSheet("""
            QDialog {
                background-color: #1e1e1e;
                color: #ffffff;
            }
            QLabel {
                color: #ffffff;
            }
            QProgressBar {
                border: 2px solid #2196F3;
                border-radius: 8px;
                text-align: center;
                font-weight: bold;
                font-size: 14px;
                background-color: #2d2d2d;
                color: #ffffff;
            }
            QProgressBar::chunk {
                background: qlineargradient(x1: 0, y1: 0, x2: 1, y2: 0,
                    stop: 0 #4CAF50, stop: 1 #45a049);
                border-radius: 6px;
                margin: 1px;
            }
            QPushButton {
                background-color: #f44336;
                color: white;
                padding: 8px 16px;
                border: none;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #d32f2f;
            }
        """)
        
        layout = QVBoxLayout(self)
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„
        info_label = QLabel(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {self.model_info['name']}")
        info_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #4CAF50;")
        layout.addWidget(info_label)
        
        size_label = QLabel(f"Ø­Ø¬Ù…: {self.model_info['size']}")
        size_label.setStyleSheet("font-size: 14px; color: #81c784;")
        layout.addWidget(size_label)
        
        # Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        layout.addWidget(self.progress_bar)
        
        # Ø¨Ø±Ú†Ø³Ø¨ ÙˆØ¶Ø¹ÛŒØª
        self.status_label = QLabel("Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯...")
        self.status_label.setStyleSheet("font-size: 12px; color: #ffffff;")
        layout.addWidget(self.status_label)
        
        # Ø¯Ú©Ù…Ù‡ Ù„ØºÙˆ
        self.cancel_button = QPushButton("Ù„ØºÙˆ Ø¯Ø§Ù†Ù„ÙˆØ¯")
        self.cancel_button.clicked.connect(self.cancel_download)
        layout.addWidget(self.cancel_button)
        
    def start_download(self):
        """Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„"""
        self.download_thread = ModelDownloadThread(self.model_id, self.model_info)
        self.download_thread.progress.connect(self.update_progress)
        self.download_thread.status.connect(self.update_status)
        self.download_thread.finished.connect(self.download_finished)
        self.download_thread.start()
        
    def update_progress(self, value):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
        self.progress_bar.setValue(value)
        
    def update_status(self, message):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª"""
        self.status_label.setText(message)
        
    def cancel_download(self):
        """Ù„ØºÙˆ Ø¯Ø§Ù†Ù„ÙˆØ¯"""
        if self.download_thread and self.download_thread.isRunning():
            self.download_thread.terminate()
        self.reject()
        
    def download_finished(self, success, message):
        """Ù¾Ø§ÛŒØ§Ù† Ø¯Ø§Ù†Ù„ÙˆØ¯"""
        if success:
            self.accept()
        else:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.critical(self, "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯", message)
            self.reject()

class ModelDownloadThread(QThread):
    """Thread Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
    progress = Signal(int)
    status = Signal(str)
    finished = Signal(bool, str)
    
    def __init__(self, model_id, model_info):
        super().__init__()
        self.model_id = model_id
        self.model_info = model_info
        
    def run(self):
        try:
            self.status.emit("Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯...")
            self.progress.emit(5)
            
            if self.model_info["type"] == "Whisper":
                success, message = self._download_whisper_with_progress()
            elif self.model_info["type"] == "Vosk":
                success, message = self._download_vosk_with_progress()
            elif self.model_info["type"] == "HuggingFace":
                success, message = self._download_huggingface_with_progress()
            else:
                success, message = False, f"Ù†ÙˆØ¹ Ù…Ø¯Ù„ {self.model_info['type']} Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯"
                
            self.finished.emit(success, message)
            
        except Exception as e:
            self.finished.emit(False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {str(e)}")
    
    def _download_whisper_with_progress(self):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Whisper Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
        try:
            import whisper
            
            model_name = self.model_id.replace("whisper_", "")
            if model_name == "large_v2":
                model_name = "large-v2"
            elif model_name == "large_v3":
                model_name = "large-v3"
            
            self.status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Whisper {model_name}...")
            self.progress.emit(20)
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
            model = whisper.load_model(model_name)
            
            self.progress.emit(100)
            self.status.emit("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
            
            return True, f"Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯"
            
        except Exception as e:
            return False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Whisper: {str(e)}"
    
    def _download_vosk_with_progress(self):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Vosk Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
        try:
            import requests
            import zipfile
            from pathlib import Path
            
            models_dir = Path.home() / ".vosk" / "models"
            models_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = models_dir / self.model_info["name"]
            
            # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
            if model_path.exists():
                self.progress.emit(100)
                self.status.emit("Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡!")
                return True, f"Ù…Ø¯Ù„ {self.model_info['name']} Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡"
            
            self.status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ {self.model_info['name']}...")
            self.progress.emit(10)
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            response = requests.get(self.model_info["url"], stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded_size = 0
            
            zip_path = models_dir / f"{self.model_info['name']}.zip"
            
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        
                        if total_size > 0:
                            progress = int((downloaded_size / total_size) * 70) + 10  # 10-80%
                            self.progress.emit(progress)
            
            self.status.emit("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¯Ù„...")
            self.progress.emit(85)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(models_dir)
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ zip
            zip_path.unlink()
            
            self.progress.emit(100)
            self.status.emit("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
            
            return True, f"Ù…Ø¯Ù„ {self.model_info['name']} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯"
            
        except Exception as e:
            return False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Vosk: {str(e)}"
    
    def _download_huggingface_with_progress(self):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Hugging Face Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
        try:
            from transformers import AutoModel, AutoTokenizer
            import os
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø² URL
            model_url = self.model_info["url"]
            if not model_url.startswith("huggingface://"):
                return False, "URL Ù…Ø¯Ù„ Hugging Face Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª"
            
            model_name = model_url.replace("huggingface://", "")
            
            self.status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Hugging Face {model_name}...")
            self.progress.emit(20)
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ tokenizer
            self.status.emit("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ tokenizer...")
            self.progress.emit(40)
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
            self.status.emit("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„...")
            self.progress.emit(70)
            model = AutoModel.from_pretrained(model_name)
            
            self.progress.emit(100)
            self.status.emit("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
            
            return True, f"Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯"
            
        except Exception as e:
            return False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Hugging Face: {str(e)}"

class DownloadedModelsManager(QDialog):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡"""
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡")
        self.setModal(True)
        self.resize(700, 500)
        self.setup_ui()
        self.refresh_models()
        
    def setup_ui(self):
        self.setStyleSheet("""
            QDialog {
                background-color: #1e1e1e;
                color: #ffffff;
            }
            QLabel {
                color: #ffffff;
            }
            QListWidget {
                background-color: #2d2d2d;
                border: 1px solid #444444;
                border-radius: 8px;
                padding: 5px;
                color: #ffffff;
                font-size: 14px;
            }
            QListWidget::item {
                padding: 8px;
                border-bottom: 1px solid #444444;
            }
            QListWidget::item:selected {
                background-color: #2196F3;
                color: #ffffff;
            }
            QPushButton {
                background-color: #4CAF50;
                color: white;
                padding: 10px 20px;
                border: none;
                border-radius: 6px;
                font-weight: bold;
                font-size: 14px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
            QPushButton:pressed {
                background-color: #3d8b40;
            }
            QPushButton#clear_button {
                background-color: #f44336;
            }
            QPushButton#clear_button:hover {
                background-color: #d32f2f;
            }
        """)
        
        layout = QVBoxLayout(self)
        
        # Ø¹Ù†ÙˆØ§Ù†
        title_label = QLabel("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡")
        title_label.setStyleSheet("font-size: 18px; font-weight: bold; color: #4CAF50; margin-bottom: 10px;")
        layout.addWidget(title_label)
        
        # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
        self.models_list = QListWidget()
        layout.addWidget(self.models_list)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        self.open_folder_button = QPushButton("ğŸ“ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙÙˆÙ„Ø¯Ø±")
        self.open_folder_button.clicked.connect(self.open_models_folder)
        button_layout.addWidget(self.open_folder_button)
        
        self.refresh_button = QPushButton("ğŸ”„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ")
        self.refresh_button.clicked.connect(self.refresh_models)
        button_layout.addWidget(self.refresh_button)
        
        self.clear_button = QPushButton("ğŸ—‘ï¸ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡")
        self.clear_button.setObjectName("clear_button")
        self.clear_button.clicked.connect(self.clear_all_models)
        button_layout.addWidget(self.clear_button)
        
        layout.addLayout(button_layout)
        
        # Ø¯Ú©Ù…Ù‡ Ø¨Ø³ØªÙ†
        close_button = QPushButton("Ø¨Ø³ØªÙ†")
        close_button.clicked.connect(self.accept)
        layout.addWidget(close_button)
        
    def refresh_models(self):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡"""
        self.models_list.clear()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk
        vosk_dir = Path.home() / ".vosk" / "models"
        if vosk_dir.exists():
            for model_dir in vosk_dir.iterdir():
                if model_dir.is_dir():
                    model_info = self.get_model_info("vosk", model_dir.name)
                    if model_info:
                        item_text = f"ğŸ¯ {model_info['name']} ({model_info['size']}) - {model_info['language']}"
                        item = QListWidgetItem(item_text)
                        item.setData(Qt.UserRole, ("vosk", model_dir.name, str(model_dir)))
                        self.models_list.addItem(item)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper
        whisper_dir = Path.home() / ".cache" / "whisper"
        if whisper_dir.exists():
            for model_file in whisper_dir.glob("*.pt"):
                model_name = model_file.stem
                model_info = self.get_model_info("whisper", model_name)
                if model_info:
                    item_text = f"ğŸ¤ {model_info['name']} ({model_info['size']}) - {model_info['language']}"
                    item = QListWidgetItem(item_text)
                    item.setData(Qt.UserRole, ("whisper", model_name, str(model_file)))
                    self.models_list.addItem(item)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face
        hf_cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
        if hf_cache_dir.exists():
            for model_dir in hf_cache_dir.iterdir():
                if model_dir.is_dir():
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø² Ù†Ø§Ù… ÙÙˆÙ„Ø¯Ø±
                    model_name = model_dir.name.replace("--", "/")
                    model_info = self.get_model_info("huggingface", model_name)
                    if model_info:
                        item_text = f"ğŸ¤— {model_info['name']} ({model_info['size']}) - {model_info['language']}"
                        item = QListWidgetItem(item_text)
                        item.setData(Qt.UserRole, ("huggingface", model_name, str(model_dir)))
                        self.models_list.addItem(item)
        
        # Ù†Ù…Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        count = self.models_list.count()
        if count == 0:
            self.models_list.addItem("Ù‡ÛŒÚ† Ù…Ø¯Ù„ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        else:
            self.models_list.insertItem(0, f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡: {count}")
            
    def get_model_info(self, model_type, model_name):
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„"""
        for model_id, info in ModelDownloader.DOWNLOADABLE_MODELS.items():
            if info["type"] == model_type.title():
                if model_type == "whisper":
                    whisper_name = model_id.replace("whisper_", "")
                    if whisper_name == "large_v2":
                        whisper_name = "large-v2"
                    elif whisper_name == "large_v3":
                        whisper_name = "large-v3"
                    if whisper_name == model_name:
                        return info
                elif model_type == "vosk":
                    if info["name"] == model_name:
                        return info
                elif model_type == "huggingface":
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø² URL
                    model_url = info["url"]
                    if model_url.startswith("huggingface://"):
                        hf_model_name = model_url.replace("huggingface://", "")
                        if hf_model_name == model_name:
                            return info
        return None
        
    def open_models_folder(self):
        """Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙÙˆÙ„Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        import subprocess
        import platform
        import os
        
        current_item = self.models_list.currentItem()
        if not current_item or not current_item.data(Qt.UserRole):
            # Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙÙˆÙ„Ø¯Ø± Ø§ØµÙ„ÛŒ - Ø§ÙˆÙ„ Vosk Ø±Ø§ Ú†Ú© Ú©Ù†
            models_dir = Path.home() / ".vosk" / "models"
            if not models_dir.exists():
                models_dir = Path.home() / ".cache" / "whisper"
                # Ø§Ú¯Ø± ÙÙˆÙ„Ø¯Ø± whisper Ù‡Ù… ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†
                if not models_dir.exists():
                    models_dir.mkdir(parents=True, exist_ok=True)
        else:
            model_type, model_name, model_path = current_item.data(Qt.UserRole)
            models_dir = Path(model_path).parent
        
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ ÙÙˆÙ„Ø¯Ø±
        if not models_dir.exists():
            try:
                models_dir.mkdir(parents=True, exist_ok=True)
            except Exception as e:
                QMessageBox.warning(self, "Ø®Ø·Ø§", f"Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÙÙˆÙ„Ø¯Ø± Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø±Ø¯:\n{str(e)}")
                return
        
        try:
            if platform.system() == "Windows":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² os.startfile Ú©Ù‡ Ø¨Ù‡ØªØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                os.startfile(str(models_dir))
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", str(models_dir)], check=True)
            else:  # Linux
                subprocess.run(["xdg-open", str(models_dir)], check=True)
        except Exception as e:
            # Ø§Ú¯Ø± os.startfile Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ Ø§Ø² subprocess Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            try:
                if platform.system() == "Windows":
                    subprocess.run(["explorer", str(models_dir)], check=True)
                elif platform.system() == "Darwin":
                    subprocess.run(["open", str(models_dir)], check=True)
                else:
                    subprocess.run(["xdg-open", str(models_dir)], check=True)
            except Exception as e2:
                QMessageBox.warning(self, "Ø®Ø·Ø§", f"Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÙÙˆÙ„Ø¯Ø± Ø±Ø§ Ø¨Ø§Ø² Ú©Ø±Ø¯:\n{str(e2)}")
            
    def clear_all_models(self):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        reply = QMessageBox.question(
            self, "ØªØ£ÛŒÛŒØ¯ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù†", 
            "Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯ØŸ\nØ§ÛŒÙ† Ø¹Ù…Ù„ Ù‚Ø§Ø¨Ù„ Ø¨Ø§Ø²Ú¯Ø´Øª Ù†ÛŒØ³Øª!",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            try:
                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk
                vosk_dir = Path.home() / ".vosk" / "models"
                if vosk_dir.exists():
                    import shutil
                    shutil.rmtree(vosk_dir)
                
                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper
                whisper_dir = Path.home() / ".cache" / "whisper"
                if whisper_dir.exists():
                    import shutil
                    shutil.rmtree(whisper_dir)
                
                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face
                hf_cache_dir = Path.home() / ".cache" / "huggingface"
                if hf_cache_dir.exists():
                    import shutil
                    shutil.rmtree(hf_cache_dir)
                
                QMessageBox.information(self, "Ù…ÙˆÙÙ‚", "Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ù¾Ø§Ú© Ø´Ø¯Ù†Ø¯.")
                self.refresh_models()
                
            except Exception as e:
                QMessageBox.critical(self, "Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§:\n{str(e)}")

class ModelSelectionDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Speech-to-Text")
        self.setModal(True)
        self.resize(600, 500)
        
        # ØªÙ… Ø¯Ø§Ø±Ú© Ø¨Ø±Ø§ÛŒ Ú©Ù„ Ø¯ÛŒØ§Ù„ÙˆÚ¯
        self.setStyleSheet("""
            QDialog {
                background-color: #1e1e1e;
                color: #ffffff;
            }
            QLabel {
                color: #ffffff;
            }
        """)
        
        layout = QVBoxLayout(self)
        
        # ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„
        filter_layout = QHBoxLayout()
        
        # Ú†Ú© Ø¨Ø§Ú©Ø³ Ø²Ø¨Ø§Ù†
        self.checkbox_persian = QCheckBox("ÙØ§Ø±Ø³ÛŒ")
        self.checkbox_persian.setChecked(True)
        self.checkbox_persian.setStyleSheet("""
            QCheckBox {
                font-weight: bold; 
                color: #81c784;
                font-size: 14px;
                padding: 5px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #81c784;
                border-radius: 3px;
                background-color: #2b2b2b;
            }
            QCheckBox::indicator:checked {
                background-color: #81c784;
                border: 2px solid #4caf50;
            }
            QCheckBox::indicator:hover {
                border: 2px solid #a5d6a7;
            }
        """)
        self.checkbox_persian.stateChanged.connect(self.filter_models)
        
        self.checkbox_english = QCheckBox("Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ")
        self.checkbox_english.setChecked(True)
        self.checkbox_english.setStyleSheet("""
            QCheckBox {
                font-weight: bold; 
                color: #64b5f6;
                font-size: 14px;
                padding: 5px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #64b5f6;
                border-radius: 3px;
                background-color: #2b2b2b;
            }
            QCheckBox::indicator:checked {
                background-color: #64b5f6;
                border: 2px solid #2196f3;
            }
            QCheckBox::indicator:hover {
                border: 2px solid #90caf9;
            }
        """)
        self.checkbox_english.stateChanged.connect(self.filter_models)
        
        self.checkbox_multilingual = QCheckBox("Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡")
        self.checkbox_multilingual.setChecked(True)
        self.checkbox_multilingual.setStyleSheet("""
            QCheckBox {
                font-weight: bold; 
                color: #ffd54f;
                font-size: 14px;
                padding: 5px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #ffd54f;
                border-radius: 3px;
                background-color: #2b2b2b;
            }
            QCheckBox::indicator:checked {
                background-color: #ffd54f;
                border: 2px solid #ffc107;
            }
            QCheckBox::indicator:hover {
                border: 2px solid #fff176;
            }
        """)
        self.checkbox_multilingual.stateChanged.connect(self.filter_models)
        
        # Ú†Ú© Ø¨Ø§Ú©Ø³ Ù†ÙˆØ¹ Ø§ØªØµØ§Ù„
        self.checkbox_online = QCheckBox("Ø¢Ù†Ù„Ø§ÛŒÙ†")
        self.checkbox_online.setChecked(True)
        self.checkbox_online.setStyleSheet("""
            QCheckBox {
                font-weight: bold; 
                color: #ff8a65;
                font-size: 14px;
                padding: 5px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #ff8a65;
                border-radius: 3px;
                background-color: #2b2b2b;
            }
            QCheckBox::indicator:checked {
                background-color: #ff8a65;
                border: 2px solid #ff5722;
            }
            QCheckBox::indicator:hover {
                border: 2px solid #ffab91;
            }
        """)
        self.checkbox_online.stateChanged.connect(self.filter_models)
        
        self.checkbox_offline = QCheckBox("Ø¢ÙÙ„Ø§ÛŒÙ†")
        self.checkbox_offline.setChecked(True)
        self.checkbox_offline.setStyleSheet("""
            QCheckBox {
                font-weight: bold; 
                color: #9575cd;
                font-size: 14px;
                padding: 5px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #9575cd;
                border-radius: 3px;
                background-color: #2b2b2b;
            }
            QCheckBox::indicator:checked {
                background-color: #9575cd;
                border: 2px solid #7e57c2;
            }
            QCheckBox::indicator:hover {
                border: 2px solid #b39ddb;
            }
        """)
        self.checkbox_offline.stateChanged.connect(self.filter_models)
        
        # Ø¨Ø±Ú†Ø³Ø¨ Ø²Ø¨Ø§Ù†
        lang_label = QLabel("Ø²Ø¨Ø§Ù†:")
        lang_label.setStyleSheet("color: #ffffff; font-weight: bold; font-size: 14px; padding: 5px;")
        filter_layout.addWidget(lang_label)
        filter_layout.addWidget(self.checkbox_persian)
        filter_layout.addWidget(self.checkbox_english)
        filter_layout.addWidget(self.checkbox_multilingual)
        filter_layout.addStretch()
        
        # Ø¨Ø±Ú†Ø³Ø¨ Ù†ÙˆØ¹
        type_label = QLabel("Ù†ÙˆØ¹:")
        type_label.setStyleSheet("color: #ffffff; font-weight: bold; font-size: 14px; padding: 5px;")
        filter_layout.addWidget(type_label)
        filter_layout.addWidget(self.checkbox_online)
        filter_layout.addWidget(self.checkbox_offline)
        
        layout.addLayout(filter_layout)
        
        # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Speech-to-Text (ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
        self.model_list = QListWidget()
        self.model_list.setMinimumHeight(300)
        self.model_list.setStyleSheet("""
            QListWidget {
                background-color: #2b2b2b;
                border: 2px solid #444;
                border-radius: 8px;
                padding: 8px;
                color: #ffffff;
                font-size: 13px;
                font-family: 'Segoe UI', Arial, sans-serif;
            }
            QListWidget::item {
                padding: 12px 8px;
                border-bottom: 1px solid #444;
                border-radius: 4px;
                margin: 2px 0px;
                color: #ffffff;
                background-color: #3a3a3a;
            }
            QListWidget::item:hover {
                background-color: #4a4a4a;
                border: 1px solid #666;
            }
            QListWidget::item:selected {
                background-color: #1976d2;
                color: #ffffff;
                border: 2px solid #42a5f5;
                font-weight: bold;
            }
            QListWidget::item:selected:hover {
                background-color: #1565c0;
            }
        """)
        layout.addWidget(self.model_list)
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù†
        self.all_models = [
            # Vosk Models (Ø¢ÙÙ„Ø§ÛŒÙ†)
            ("vosk_persian", "âœ… Vosk Persian - Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ (1.13 GB)", "persian", "offline"),
            ("vosk_small", "âš ï¸ Vosk Small - ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (40 MB)", "english", "offline"),
            ("vosk_large", "âš ï¸ Vosk Large - ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (1.8 GB)", "english", "offline"),
            
            # Whisper Models (Ø¢ÙÙ„Ø§ÛŒÙ† - Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
            ("whisper_tiny", "âš ï¸ Whisper Tiny - Ø®ÛŒÙ„ÛŒ Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ (75 MB)", "both", "offline"),
            ("whisper_base", "âš ï¸ Whisper Base - Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ (142 MB)", "both", "offline"),
            ("whisper_small", "âœ… Whisper Small - ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨ (466 MB)", "both", "offline"),
            ("whisper_medium", "âœ… Whisper Medium - Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ (1.5 GB)", "both", "offline"),
            ("whisper_large", "âœ… Whisper Large - Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¯Ù‚Øª (3.1 GB)", "both", "offline"),
            ("whisper_large_v2", "âœ… Whisper Large V2 - Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡ (3.1 GB)", "both", "offline"),
            ("whisper_large_v3", "âœ… Whisper Large V3 - Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡ (3.1 GB)", "both", "offline"),
            
            # Hugging Face Transformers (Ø¢ÙÙ„Ø§ÛŒÙ†)
            ("hf_wav2vec2_persian", "âœ… Wav2Vec2 Persian - Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ (1.2 GB)", "persian", "offline"),
            ("hf_wav2vec2_persian_v3", "ğŸ† Wav2Vec2 Persian V3 - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª ÙØ§Ø±Ø³ÛŒ (1.2 GB)", "persian", "offline"),
            ("hf_wav2vec2_persian_jonatas", "â­ Wav2Vec2 Persian Jonatas - Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ (1.2 GB)", "persian", "offline"),
            ("hf_whisper_large_v3_persian", "âœ… Whisper Large V3 Persian - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª (3.1 GB)", "persian", "offline"),
            ("hf_whisper_large_v3_persian_alt", "âœ… Whisper Large V3 Persian Alt - Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† (3.1 GB)", "persian", "offline"),
            ("hf_whisper_large_persian_steja", "âœ… Whisper Large Persian Steja - Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ (3.1 GB)", "persian", "offline"),
            ("hf_wav2vec2_persian_alt", "âš ï¸ Wav2Vec2 Multilingual - Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡ (1.2 GB)", "both", "offline"),
            ("hf_whisper_tiny", "âš ï¸ Whisper Tiny HF - Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ (75 MB)", "both", "offline"),
            ("hf_whisper_base", "âš ï¸ Whisper Base HF - Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ (142 MB)", "both", "offline"),
            ("hf_whisper_small", "âœ… Whisper Small HF - ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨ (466 MB)", "both", "offline"),
            ("hf_whisper_medium", "âœ… Whisper Medium HF - Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ (1.5 GB)", "both", "offline"),
            ("hf_whisper_large", "âœ… Whisper Large HF - Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¯Ù‚Øª (3.1 GB)", "both", "offline"),
            ("hf_whisper_large_v2", "âœ… Whisper Large V2 HF - Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡ (3.1 GB)", "both", "offline"),
            ("hf_whisper_large_v3", "âœ… Whisper Large V3 HF - Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡ (3.1 GB)", "both", "offline"),
            
            # SpeechRecognition (Ø¢Ù†Ù„Ø§ÛŒÙ†)
            ("speechrecognition_google", "ğŸŒ Google Speech - Ø±Ø§ÛŒÚ¯Ø§Ù† 60Ø¯Ù‚ÛŒÙ‚Ù‡/Ù…Ø§Ù‡ (Ø¢Ù†Ù„Ø§ÛŒÙ†)", "both", "online"),
            ("speechrecognition_sphinx", "âš ï¸ CMU Sphinx - ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (100 MB)", "english", "offline"),
            ("speechrecognition_wit", "ğŸŒ Wit.ai - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ (Ø¢Ù†Ù„Ø§ÛŒÙ†)", "both", "online"),
            ("speechrecognition_azure", "ğŸŒ Azure Speech - Ø±Ø§ÛŒÚ¯Ø§Ù† 5Ø³Ø§Ø¹Øª/Ù…Ø§Ù‡ (Ø¢Ù†Ù„Ø§ÛŒÙ†)", "both", "online"),
            ("speechrecognition_bing", "ğŸŒ Bing Speech - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ (Ø¢Ù†Ù„Ø§ÛŒÙ†)", "both", "online"),
            ("speechrecognition_houndify", "ğŸŒ Houndify - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ (Ø¢Ù†Ù„Ø§ÛŒÙ†)", "both", "online"),
            ("speechrecognition_ibm", "ğŸŒ IBM Speech - Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ (Ø¢Ù†Ù„Ø§ÛŒÙ†)", "both", "online"),
            
            # Silero STT (Ø¢ÙÙ„Ø§ÛŒÙ†)
            ("silero_stt_en", "âš ï¸ Silero STT English - ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (50 MB)", "english", "offline"),
            ("silero_stt_multilingual", "âœ… Silero STT Multilingual - Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ÙØ§Ø±Ø³ÛŒ (200 MB)", "both", "offline"),
            
            
            
        ]
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ù„ÛŒØ³Øª
        self.populate_model_list()
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
        config = ConfigManager.load_config()
        last_model = config.get("selected_model", "vosk_persian")
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø¢Ø®Ø±
        for i in range(self.model_list.count()):
            item = self.model_list.item(i)
            if item.data(Qt.UserRole) == last_model:
                self.model_list.setCurrentItem(item)
                break
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        self.ok_button = QPushButton("ØªØ£ÛŒÛŒØ¯")
        self.ok_button.setStyleSheet("""
            QPushButton {
                background-color: #4CAF50;
                color: white;
                padding: 12px 24px;
                border: none;
                border-radius: 6px;
                font-weight: bold;
                font-size: 14px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
            QPushButton:pressed {
                background-color: #3d8b40;
            }
        """)
        self.ok_button.clicked.connect(self.accept)
        
        self.cancel_button = QPushButton("Ù„ØºÙˆ")
        self.cancel_button.setStyleSheet("""
            QPushButton {
                background-color: #f44336;
                color: white;
                padding: 12px 24px;
                border: none;
                border-radius: 6px;
                font-weight: bold;
                font-size: 14px;
            }
            QPushButton:hover {
                background-color: #da190b;
            }
            QPushButton:pressed {
                background-color: #c1170a;
            }
        """)
        self.cancel_button.clicked.connect(self.reject)
        
        button_layout.addWidget(self.ok_button)
        button_layout.addWidget(self.cancel_button)
        layout.addLayout(button_layout)
    
    def populate_model_list(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ù„ÛŒØ³Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÙ„ØªØ±Ù‡Ø§"""
        self.model_list.clear()
        
        for model_id, description, language, connection_type in self.all_models:
            # Ø¨Ø±Ø±Ø³ÛŒ ÙÛŒÙ„ØªØ± Ø²Ø¨Ø§Ù†
            language_match = False
            if language == "both" and self.checkbox_multilingual.isChecked():
                language_match = True
            elif language == "persian" and self.checkbox_persian.isChecked():
                language_match = True
            elif language == "english" and self.checkbox_english.isChecked():
                language_match = True
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙÛŒÙ„ØªØ± Ù†ÙˆØ¹ Ø§ØªØµØ§Ù„
            connection_match = False
            if connection_type == "online" and self.checkbox_online.isChecked():
                connection_match = True
            elif connection_type == "offline" and self.checkbox_offline.isChecked():
                connection_match = True
            
            # Ø§Ú¯Ø± Ù‡Ø± Ø¯Ùˆ ÙÛŒÙ„ØªØ± Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø´ØªØŒ Ù…Ø¯Ù„ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if language_match and connection_match:
                item = QListWidgetItem(f"{model_id} - {description}")
                item.setData(Qt.UserRole, model_id)
                
                # Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§ØªØµØ§Ù„
                if connection_type == "online":
                    # Ø¢Ù†Ù„Ø§ÛŒÙ† - Ù†Ø§Ø±Ù†Ø¬ÛŒ/Ù‚Ø±Ù…Ø² ØªÛŒØ±Ù‡
                    item.setBackground(QColor("#4a2c2a"))  # Ù‚Ø±Ù…Ø² ØªÛŒØ±Ù‡
                    item.setForeground(QColor("#ff8a65"))  # Ù†Ø§Ø±Ù†Ø¬ÛŒ Ø±ÙˆØ´Ù†
                else:
                    # Ø¢ÙÙ„Ø§ÛŒÙ† - Ø¨Ù†ÙØ´/Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡
                    item.setBackground(QColor("#2a2c4a"))  # Ø¨Ù†ÙØ´ ØªÛŒØ±Ù‡
                    item.setForeground(QColor("#9575cd"))  # Ø¨Ù†ÙØ´ Ø±ÙˆØ´Ù†
                
                # Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ø¨Ø§Ù†
                if language == "persian":
                    # ÙØ§Ø±Ø³ÛŒ - Ø³Ø¨Ø²
                    item.setForeground(QColor("#81c784"))  # Ø³Ø¨Ø² Ø±ÙˆØ´Ù†
                elif language == "english":
                    # Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ - Ø¢Ø¨ÛŒ
                    item.setForeground(QColor("#64b5f6"))  # Ø¢Ø¨ÛŒ Ø±ÙˆØ´Ù†
                elif language == "both":
                    # Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡ - Ø²Ø±Ø¯
                    item.setForeground(QColor("#ffd54f"))  # Ø²Ø±Ø¯ Ø±ÙˆØ´Ù†
                
                self.model_list.addItem(item)
    
    def filter_models(self):
        """ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú†Ú© Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§"""
        self.populate_model_list()
    
    def get_selected_model(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡"""
        current_item = self.model_list.currentItem()
        if current_item:
            return current_item.data(Qt.UserRole)
        return None


def improve_persian_text(text):
    """Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ ØªØµØ­ÛŒØ­ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³Ø§Ø¯Ù‡"""
    if not text or not text.strip():
        return text
    
    # ØªØµØ­ÛŒØ­ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
    if PERSIAN_TOOLS_AVAILABLE:
        text = characters.ar_to_fa(text)  # ØªØ¨Ø¯ÛŒÙ„ Ø¹Ø±Ø¨ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
        text = digits.en_to_fa(text)  # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
    
    # ØªØµØ­ÛŒØ­ ÙØ§ØµÙ„Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø³Ø§Ø¯Ù‡
    text = text.replace("  ", " ")  # Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
    text = text.replace(" .", ".")  # ØªØµØ­ÛŒØ­ Ù†Ù‚Ø·Ù‡
    text = text.replace(" ,", ",")  # ØªØµØ­ÛŒØ­ ÙˆÛŒØ±Ú¯ÙˆÙ„
    text = text.replace(" :", ":")  # ØªØµØ­ÛŒØ­ Ø¯Ùˆ Ù†Ù‚Ø·Ù‡
    text = text.replace(" ;", ";")  # ØªØµØ­ÛŒØ­ Ù†Ù‚Ø·Ù‡â€ŒÙˆÛŒØ±Ú¯ÙˆÙ„
    text = text.replace(" !", "!")  # ØªØµØ­ÛŒØ­ Ø¹Ù„Ø§Ù…Øª ØªØ¹Ø¬Ø¨
    text = text.replace(" ?", "?")  # ØªØµØ­ÛŒØ­ Ø¹Ù„Ø§Ù…Øª Ø³ÙˆØ§Ù„
    
    return text.strip()


class TranscribeThread(QThread):
    progress = Signal(int)
    finished = Signal(str)
    download_status = Signal(str)

    def __init__(self, audio_path, model_name="vosk_persian"):
        super().__init__()
        self.audio_path = audio_path
        self.model_name = model_name
        self.model = None
        self._pause = False
        self._stop = False
        self.silero_models = {}  # Cache Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Silero

    def run(self):
        try:
            self.progress.emit(5)
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
            if self.model_name.startswith("whisper_"):
                whisper_model = self.model_name.replace("whisper_", "")
                # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Whisper
                if whisper_model == "large_v2":
                    whisper_model = "large-v2"
                elif whisper_model == "large_v3":
                    whisper_model = "large-v3"
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Whisper {whisper_model}...")
                
                self.model = whisper.load_model(whisper_model)
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ù…Ø¯Ù„ Whisper {whisper_model} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            elif self.model_name.startswith("google_"):
                if not GOOGLE_SPEECH_AVAILABLE:
                    self.finished.emit("Error: Google Speech-to-Text not installed. Install with: pip install google-cloud-speech")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Speech {self.model_name}...")
                
                self.model = "google"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Google Speech {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("vosk_"):
                if not VOSK_AVAILABLE:
                    self.finished.emit("Error: Vosk not installed. Install with: pip install vosk")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Vosk {self.model_name}...")
                
                self.model = "vosk"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vosk
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ù…Ø¯Ù„ Vosk {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("azure_"):
                if not AZURE_SPEECH_AVAILABLE:
                    self.finished.emit("Error: Azure Speech not installed. Install with: pip install azure-cognitiveservices-speech")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Azure Speech {self.model_name}...")
                
                self.model = "azure"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Azure Speech {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("assemblyai_"):
                if not ASSEMBLYAI_AVAILABLE:
                    self.finished.emit("Error: AssemblyAI not installed. Install with: pip install assemblyai")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ AssemblyAI {self.model_name}...")
                
                self.model = "assemblyai"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AssemblyAI
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"AssemblyAI {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("hf_"):
                if not HUGGINGFACE_AVAILABLE:
                    self.finished.emit("Error: Hugging Face Transformers not installed. Install with: pip install transformers torch")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Hugging Face {self.model_name}...")
                
                self.model = "huggingface"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ù…Ø¯Ù„ Hugging Face {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("speechrecognition_"):
                if not SPEECHRECOGNITION_AVAILABLE:
                    self.finished.emit("Error: SpeechRecognition not installed. Install with: pip install SpeechRecognition")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ SpeechRecognition {self.model_name}...")
                
                self.model = "speechrecognition"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SpeechRecognition
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ù…Ø¯Ù„ SpeechRecognition {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("silero_"):
                if not SILERO_AVAILABLE:
                    self.finished.emit("Error: Silero STT not installed. Install with: pip install torchaudio")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Silero STT {self.model_name}...")
                
                self.model = "silero"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Silero
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ù…Ø¯Ù„ Silero STT {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("kaldi_"):
                if not KALDI_AVAILABLE:
                    self.finished.emit("Error: Kaldi not installed. Install with: pip install kaldi-io")
                    return
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Kaldi {self.model_name}...")
                
                self.model = "kaldi"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Kaldi
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ù…Ø¯Ù„ Kaldi {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            elif self.model_name.startswith("iranian_"):
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³Ø±ÙˆÛŒØ³ Ø§ÛŒØ±Ø§Ù†ÛŒ {self.model_name}...")
                
                self.model = "iranian"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
                
                # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
                if hasattr(self, 'download_status'):
                    self.download_status.emit(f"Ø³Ø±ÙˆÛŒØ³ Ø§ÛŒØ±Ø§Ù†ÛŒ {self.model_name} Ø¢Ù…Ø§Ø¯Ù‡")
            else:
                self.finished.emit(f"Error: Unknown model {self.model_name}")
                return
                
            self.progress.emit(10)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ WAV 16kHz Mono Ø¯Ø± ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                temp_wav = tmp.name

            subprocess.run([
                "ffmpeg", "-y", "-i", str(self.audio_path),
                "-ar", "16000", "-ac", "1", 
                "-af", "highpass=f=80,lowpass=f=8000",  # ÙÛŒÙ„ØªØ± ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©ÛŒÙÛŒØª
                temp_wav
            ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            self.progress.emit(35)

            # ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†
            if self.model == "google":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google Speech-to-Text
                text = self.transcribe_with_google(temp_wav)
            elif self.model == "vosk":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vosk
                text = self.transcribe_with_vosk(temp_wav)
            elif self.model == "azure":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure Speech
                text = self.transcribe_with_azure(temp_wav)
            elif self.model == "assemblyai":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AssemblyAI
                text = self.transcribe_with_assemblyai(temp_wav)
            elif self.model == "huggingface":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face
                text = self.transcribe_with_huggingface(temp_wav)
            elif self.model == "speechrecognition":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SpeechRecognition
                text = self.transcribe_with_speechrecognition(temp_wav)
            elif self.model == "silero":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Silero STT
                text = self.transcribe_with_silero(temp_wav)
            elif self.model == "kaldi":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Kaldi
                text = self.transcribe_with_kaldi(temp_wav)
            elif self.model == "iranian":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
                text = self.transcribe_with_iranian(temp_wav)
            else:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Whisper
                result = self.model.transcribe(
                    temp_wav,
                    language="fa",  # Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ
                    initial_prompt="Ø§ÛŒÙ† ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø±Ø§ Ø¨Ø§ Ø§Ù…Ù„Ø§ÛŒ ØµØ­ÛŒØ­ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯.",
                    temperature=0.0,  # Ú©Ø§Ù‡Ø´ Ø®Ù„Ø§Ù‚ÛŒØª Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
                    beam_size=5,  # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª
                    best_of=3,  # ØªØ³Øª Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø§Ø± Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡
                    patience=1.0,  # ØµØ¨Ø± Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
                    length_penalty=1.0,  # ØªÙ†Ø¸ÛŒÙ… Ø·ÙˆÙ„ Ù…ØªÙ†
                    suppress_tokens=[-1],  # Ø­Ø°Ù ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
                    word_timestamps=True,  # ØªØ´Ø®ÛŒØµ Ø¨Ù‡ØªØ± Ú©Ù„Ù…Ø§Øª
                    no_speech_threshold=0.6,  # Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ´Ø®ÛŒØµ Ø³Ú©ÙˆØª
                    logprob_threshold=-1.0,  # Ø¢Ø³ØªØ§Ù†Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ú©Ù„Ù…Ø§Øª
                    compression_ratio_threshold=2.4  # Ø¢Ø³ØªØ§Ù†Ù‡ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ
                )
                text = result["text"]
            
            # Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
            text = improve_persian_text(text)
            
            self.progress.emit(75)

            # Ù„ØºØ§Øª Ú©Ø§Ø³ØªÙˆÙ…
            with open(CUSTOM_DICT_FILE, encoding="utf-8") as f:
                custom_dict = json.load(f)
            for wrong, correct in custom_dict.items():
                text = text.replace(wrong, correct)

            # Ø¢Ù…Ø§Ø±
            words = text.split()
            word_count = len(words)

            # ØªÚ©ÛŒÙ‡ Ú©Ù„Ø§Ù…â€ŒÙ‡Ø§
            with open(RELYING_DICT_FILE, encoding="utf-8") as f:
                relying_data = json.load(f)
            relying_words = relying_data.get("ØªÚ©ÛŒÙ‡_Ú©Ù„Ø§Ù…", [])
            detected_relying = [w for w in words if w in relying_words]

            counter = collections.Counter(words)
            most_common = counter.most_common(10)

            stats = "\n\n--- Statistics ---\n"
            stats += f"Word Count: {word_count}\n"
            stats += f"Detected Pauses/Tic Words: {', '.join(detected_relying)}\n"
            stats += "Top 10 Frequent Words:\n"
            for w, c in most_common:
                stats += f"{w}: {c}\n"

            text += stats
            self.progress.emit(100)
            self.finished.emit(text)

            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            os.remove(temp_wav)

        except Exception as e:
            self.finished.emit(f"Error: {str(e)}")
    
    def transcribe_with_google(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Google Speech-to-Text"""
        try:
            client = speech.SpeechClient()
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            with open(audio_file, "rb") as audio_file_content:
                content = audio_file_content.read()
            
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ´Ø®ÛŒØµ
            audio = speech.RecognitionAudio(content=content)
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Google
            if self.model_name == "google_enhanced":
                model = "phone_call"  # Ù…Ø¯Ù„ Enhanced
            elif self.model_name == "google_phone_call":
                model = "phone_call"
            elif self.model_name == "google_medical":
                model = "medical_dictation"
            elif self.model_name == "google_video":
                model = "video"
            else:
                model = "default"  # Ù…Ø¯Ù„ Standard
            
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code="fa-IR",  # ÙØ§Ø±Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†
                model=model,
                enable_automatic_punctuation=True,
                enable_word_time_offsets=True
            )
            
            # ØªØ´Ø®ÛŒØµ
            response = client.recognize(config=config, audio=audio)
            
            # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬
            text = ""
            for result in response.results:
                text += result.alternatives[0].transcript + " "
            
            return text.strip()
            
        except Exception as e:
            error_msg = str(e)
            if "credentials" in error_msg.lower():
                return f"""Google Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… credentials

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google Speech-to-Text:

1. Ø¨Ù‡ https://console.cloud.google.com Ø¨Ø±ÙˆÛŒØ¯
2. Ù¾Ø±ÙˆÚ˜Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø³Ø§Ø²ÛŒØ¯ ÛŒØ§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯
3. API Speech-to-Text Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
4. Service Account Ø¨Ø³Ø§Ø²ÛŒØ¯ Ùˆ JSON key Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯
5. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set GOOGLE_APPLICATION_CREDENTIALS=path/to/your/key.json

ÛŒØ§ Ø§Ø² Whisper Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø¢ÙÙ„Ø§ÛŒÙ† Ùˆ Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
            else:
                return f"Google Speech Error: {error_msg}"
    
    def transcribe_with_vosk(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Vosk"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Vosk
            if not ModelDownloader.is_model_downloaded(self.model_name):
                # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ Ù†ÙˆØªÛŒÙÛŒÚ©ÛŒØ´Ù† Ø³Ø§Ø¯Ù‡
                def progress_callback(message):
                    self.download_status.emit(message)
                
                success, result = ModelDownloader.download_model(
                    self.model_name, 
                    progress_callback=progress_callback
                )
                if not success:
                    return f"Vosk Error: {result}"
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø³ÛŒØ± Ù…Ø¯Ù„
            model_path = self.get_vosk_model_path()
            if not model_path:
                return "Vosk Error: Ù…Ø¯Ù„ Vosk ÛŒØ§ÙØª Ù†Ø´Ø¯."
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
            model = vosk.Model(model_path)
            
            # ØªÙ†Ø¸ÛŒÙ… Ø²Ø¨Ø§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
            if self.model_name == "vosk_persian":
                rec = vosk.KaldiRecognizer(model, 16000)
            elif self.model_name in ["vosk_arabic", "vosk_spanish", "vosk_french", "vosk_german", 
                                   "vosk_italian", "vosk_portuguese", "vosk_russian", 
                                   "vosk_chinese", "vosk_japanese", "vosk_korean"]:
                rec = vosk.KaldiRecognizer(model, 16000)
            else:
                rec = vosk.KaldiRecognizer(model, 16000)
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            with open(audio_file, "rb") as f:
                data = f.read()
            
            # ØªØ´Ø®ÛŒØµ
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "")
            else:
                result = json.loads(rec.FinalResult())
                text = result.get("text", "")
            
            return text.strip()
            
        except Exception as e:
            return f"Vosk Error: {str(e)}"
    
    def get_vosk_model_path(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø³ÛŒØ± Ù…Ø¯Ù„ Vosk"""
        if self.model_name not in ModelDownloader.VOSK_MODELS:
            return None
        
        model_info = ModelDownloader.VOSK_MODELS[self.model_name]
        models_dir = Path.home() / ".vosk" / "models"
        model_path = models_dir / model_info["name"]
        
        if model_path.exists():
            return str(model_path)
        
        return None
    
    def transcribe_with_azure(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Azure Speech"""
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Azure (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)
            speech_key = os.getenv("AZURE_SPEECH_KEY")
            service_region = os.getenv("AZURE_SPEECH_REGION", "eastus")
            
            if not speech_key:
                return """Azure Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure Speech:

1. Ø¨Ù‡ https://portal.azure.com Ø¨Ø±ÙˆÛŒØ¯
2. Cognitive Services > Speech Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯
3. API Key Ùˆ Region Ø±Ø§ Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set AZURE_SPEECH_KEY=your_key_here
   set AZURE_SPEECH_REGION=your_region_here

ÛŒØ§ Ø§Ø² Vosk Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
            
            # ØªÙ†Ø¸ÛŒÙ… speech config
            speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
            speech_config.speech_recognition_language = "fa-IR"  # ÙØ§Ø±Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†
            
            # ØªÙ†Ø¸ÛŒÙ… audio config
            audio_config = speechsdk.audio.AudioConfig(filename=audio_file)
            
            # Ø§ÛŒØ¬Ø§Ø¯ speech recognizer
            speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
            
            # ØªØ´Ø®ÛŒØµ
            result = speech_recognizer.recognize_once()
            
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                return result.text
            elif result.reason == speechsdk.ResultReason.NoMatch:
                return "Azure Speech: ØªØ´Ø®ÛŒØµ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯"
            else:
                return f"Azure Speech Error: {result.reason}"
                
        except Exception as e:
            return f"Azure Speech Error: {str(e)}"
    
    def transcribe_with_assemblyai(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ AssemblyAI"""
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª AssemblyAI (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)
            api_key = os.getenv("ASSEMBLYAI_API_KEY")
            
            if not api_key:
                return """AssemblyAI Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AssemblyAI:

1. Ø¨Ù‡ https://www.assemblyai.com Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. API Key Ø±Ø§ Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set ASSEMBLYAI_API_KEY=your_key_here

ÛŒØ§ Ø§Ø² Vosk Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
            
            # ØªÙ†Ø¸ÛŒÙ… API key
            aai.settings.api_key = api_key
            
            # Ø§ÛŒØ¬Ø§Ø¯ transcriber
            transcriber = aai.Transcriber()
            
            # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            transcript = transcriber.transcribe(audio_file)
            
            if transcript.status == aai.TranscriptStatus.completed:
                return transcript.text
            else:
                return f"AssemblyAI Error: {transcript.status}"
                
        except Exception as e:
            return f"AssemblyAI Error: {str(e)}"
    
    def transcribe_with_huggingface(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Hugging Face Transformers"""
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
            if self.model_name == "hf_wav2vec2_persian":
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ
                try:
                    model_name = "m3hrdadfi/wav2vec2-large-xlsr-persian"
                    processor = AutoProcessor.from_pretrained(model_name)
                    model = AutoModelForCTC.from_pretrained(model_name)
                except Exception as e:
                    error_msg = str(e)
                    if "not a valid model identifier" in error_msg:
                        return f"""Hugging Face Error: Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª

Ù…Ø´Ú©Ù„: Ù…Ø¯Ù„ m3hrdadfi/wav2vec2-large-xlsr-persian ÛŒØ§ÙØª Ù†Ø´Ø¯

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ø§Ø² Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯: Wav2Vec2 Persian V3
3. Token Hugging Face Ø®ÙˆØ¯ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   huggingface-cli login
   ÛŒØ§
   hf auth login
"""
                    else:
                        return f"Hugging Face Error: {error_msg}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Vosk Persian ÛŒØ§ Whisper Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
                        
            elif self.model_name == "hf_wav2vec2_persian_v3":
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ V3 (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡)
                try:
                    model_name = "m3hrdadfi/wav2vec2-large-xlsr-persian-v3"
                    processor = AutoProcessor.from_pretrained(model_name)
                    model = AutoModelForCTC.from_pretrained(model_name)
                except Exception as e:
                    error_msg = str(e)
                    if "not a valid model identifier" in error_msg:
                        return f"""Hugging Face Error: Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ V3 Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª

Ù…Ø´Ú©Ù„: Ù…Ø¯Ù„ m3hrdadfi/wav2vec2-large-xlsr-persian-v3 ÛŒØ§ÙØª Ù†Ø´Ø¯

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Wav2Vec2 Persian (Ù†Ø³Ø®Ù‡ Ù‚Ø¨Ù„ÛŒ)
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face:
1. Ø¨Ù‡ https://huggingface.co Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Ø§Ø² Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   hf auth login
"""
                    else:
                        return f"Hugging Face Error: {error_msg}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Vosk Persian ÛŒØ§ Whisper Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
                        
            elif self.model_name == "hf_wav2vec2_persian_jonatas":
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ Jonatas (Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡)
                try:
                    model_name = "jonatasgrosman/wav2vec2-large-xlsr-53-persian"
                    processor = AutoProcessor.from_pretrained(model_name)
                    model = AutoModelForCTC.from_pretrained(model_name)
                except Exception as e:
                    error_msg = str(e)
                    if "not a valid model identifier" in error_msg:
                        return f"""Hugging Face Error: Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ Jonatas Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª

Ù…Ø´Ú©Ù„: Ù…Ø¯Ù„ jonatasgrosman/wav2vec2-large-xlsr-53-persian ÛŒØ§ÙØª Ù†Ø´Ø¯

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Wav2Vec2 Persian V3 (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†)
   â€¢ Wav2Vec2 Persian (Ù†Ø³Ø®Ù‡ Ù‚Ø¨Ù„ÛŒ)
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face:
1. Ø¨Ù‡ https://huggingface.co Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Ø§Ø² Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   hf auth login
"""
                    else:
                        return f"Hugging Face Error: {error_msg}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Vosk Persian ÛŒØ§ Whisper Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
                        
                    
            elif self.model_name == "hf_whisper_large_v3_persian":
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Whisper ÙØ§Ø±Ø³ÛŒ
                try:
                    from transformers import WhisperForConditionalGeneration, WhisperProcessor
                    model_name = "nezamisafa/whisper-large-v3-persian"
                    processor = WhisperProcessor.from_pretrained(model_name)
                    model = WhisperForConditionalGeneration.from_pretrained(model_name)
                except Exception as e:
                    error_msg = str(e)
                    if "not a valid model identifier" in error_msg:
                        return f"""Hugging Face Error: Ù…Ø¯Ù„ Whisper ÙØ§Ø±Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª

Ù…Ø´Ú©Ù„: Ù…Ø¯Ù„ nezamisafa/whisper-large-v3-persian ÛŒØ§ÙØª Ù†Ø´Ø¯

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Ø¹Ø§Ø¯ÛŒ (Hugging Face)

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face:
1. Ø¨Ù‡ https://huggingface.co Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Ø§Ø² Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   hf auth login
"""
                    else:
                        return f"Hugging Face Error: {error_msg}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Whisper Ø¹Ø§Ø¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
                        
            elif self.model_name == "hf_whisper_large_v3_persian_alt":
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Whisper ÙØ§Ø±Ø³ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
                try:
                    from transformers import WhisperForConditionalGeneration, WhisperProcessor
                    model_name = "MohammadKhosravi/whisper-large-v3-Persian"
                    processor = WhisperProcessor.from_pretrained(model_name)
                    model = WhisperForConditionalGeneration.from_pretrained(model_name)
                except Exception as e:
                    error_msg = str(e)
                    if "not a valid model identifier" in error_msg:
                        return f"""Hugging Face Error: Ù…Ø¯Ù„ Whisper ÙØ§Ø±Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª

Ù…Ø´Ú©Ù„: Ù…Ø¯Ù„ MohammadKhosravi/whisper-large-v3-Persian ÛŒØ§ÙØª Ù†Ø´Ø¯

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Ø¹Ø§Ø¯ÛŒ (Hugging Face)

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face:
1. Ø¨Ù‡ https://huggingface.co Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Ø§Ø² Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   hf auth login
"""
                    else:
                        return f"Hugging Face Error: {error_msg}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Whisper Ø¹Ø§Ø¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
                        
            elif self.model_name == "hf_whisper_large_persian_steja":
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Whisper ÙØ§Ø±Ø³ÛŒ Steja
                try:
                    from transformers import WhisperForConditionalGeneration, WhisperProcessor
                    model_name = "steja/whisper-large-persian"
                    processor = WhisperProcessor.from_pretrained(model_name)
                    model = WhisperForConditionalGeneration.from_pretrained(model_name)
                except Exception as e:
                    error_msg = str(e)
                    if "not a valid model identifier" in error_msg:
                        return f"""Hugging Face Error: Ù…Ø¯Ù„ Whisper ÙØ§Ø±Ø³ÛŒ Steja Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª

Ù…Ø´Ú©Ù„: Ù…Ø¯Ù„ steja/whisper-large-persian ÛŒØ§ÙØª Ù†Ø´Ø¯

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Wav2Vec2 Persian V3 (Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª)
   â€¢ Wav2Vec2 Persian (Ù†Ø³Ø®Ù‡ Ù‚Ø¨Ù„ÛŒ)
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face:
1. Ø¨Ù‡ https://huggingface.co Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Ø§Ø² Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   hf auth login
"""
                    else:
                        return f"Hugging Face Error: {error_msg}. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Whisper Ø¹Ø§Ø¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
                    
            elif self.model_name == "hf_wav2vec2_persian_alt":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¹Ù…ÙˆÙ…ÛŒ wav2vec2
                try:
                    model_name = "facebook/wav2vec2-large-xlsr-53"
                    processor = AutoProcessor.from_pretrained(model_name)
                    model = AutoModelForCTC.from_pretrained(model_name)
                except Exception as e:
                    return f"Hugging Face Error: Ù…Ø¯Ù„ wav2vec2 Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª ({str(e)}). Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
            else:
                # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Whisper
                from transformers import WhisperForConditionalGeneration, WhisperProcessor
                model_name = self.model_name.replace("hf_", "").replace("_hf", "")
                if model_name == "whisper_large":
                    model_name = "openai/whisper-large-v2"
                elif model_name == "whisper_large_v2":
                    model_name = "openai/whisper-large-v2"
                elif model_name == "whisper_large_v3":
                    model_name = "openai/whisper-large-v3"
                else:
                    model_name = f"openai/whisper-{model_name}"
                
                try:
                    processor = WhisperProcessor.from_pretrained(model_name)
                    model = WhisperForConditionalGeneration.from_pretrained(model_name)
                except Exception as e:
                    return f"Hugging Face Error: Ù…Ø¯Ù„ {model_name} Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª ({str(e)}). Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            try:
                import librosa
                audio, sr = librosa.load(audio_file, sr=16000)
            except ImportError:
                try:
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² soundfile Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
                    import soundfile as sf
                    audio, sr = sf.read(audio_file)
                    if sr != 16000:
                        # ØªØ¨Ø¯ÛŒÙ„ sample rate Ø¨Ù‡ 16000
                        import numpy as np
                        from scipy import signal
                        audio = signal.resample(audio, int(len(audio) * 16000 / sr))
                        sr = 16000
                except ImportError:
                    return "Hugging Face Error: Neither librosa nor soundfile is available. Install with: pip install librosa soundfile"
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´
            try:
                inputs = processor(audio, sampling_rate=sr, return_tensors="pt")
                
                # ØªØ´Ø®ÛŒØµ
                with torch.no_grad():
                    logits = model(inputs.input_values).logits
                
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†
                predicted_ids = torch.argmax(logits, dim=-1)
                text = processor.batch_decode(predicted_ids)[0]
                
                return text.strip()
            except Exception as e:
                return f"Hugging Face Error: Model processing failed - {str(e)}"
            
        except Exception as e:
            return f"Hugging Face Error: {str(e)}"
    
    def transcribe_with_speechrecognition(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ SpeechRecognition"""
        try:
            r = sr.Recognizer()
            
            with sr.AudioFile(audio_file) as source:
                audio = r.record(source)
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø±ÙˆÛŒØ³ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„
            if self.model_name == "speechrecognition_google":
                text = r.recognize_google(audio, language="fa-IR")
            elif self.model_name == "speechrecognition_sphinx":
                try:
                    text = r.recognize_sphinx(audio)
                except Exception as e:
                    if "missing PocketSphinx module" in str(e):
                        return """SpeechRecognition Error: PocketSphinx not installed

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CMU Sphinx:
1. PocketSphinx Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   pip install PocketSphinx
2. ÛŒØ§ Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)

CMU Sphinx ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø±Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
"""
                    else:
                        return f"SpeechRecognition Error: {str(e)}"
            elif self.model_name == "speechrecognition_wit":
                api_key = os.getenv("WIT_AI_KEY")
                if not api_key:
                    return """SpeechRecognition Error: Wit.ai API Key not found

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Wit.ai:
1. Ø¨Ù‡ https://wit.ai Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. API Key Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set WIT_AI_KEY=your_key_here

ÛŒØ§ Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
                text = r.recognize_wit(audio, key=api_key)
            elif self.model_name == "speechrecognition_azure":
                api_key = os.getenv("AZURE_SPEECH_KEY")
                region = os.getenv("AZURE_SPEECH_REGION")
                if not api_key or not region:
                    return """SpeechRecognition Error: Azure Speech API Key not found

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure Speech:
1. Ø¨Ù‡ https://portal.azure.com Ø¨Ø±ÙˆÛŒØ¯
2. Cognitive Services > Speech Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯
3. API Key Ùˆ Region Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set AZURE_SPEECH_KEY=your_key_here
   set AZURE_SPEECH_REGION=your_region_here

ÛŒØ§ Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
                text = r.recognize_azure(audio, key=api_key, location=region)
            elif self.model_name == "speechrecognition_bing":
                api_key = os.getenv("BING_KEY")
                if not api_key:
                    return """SpeechRecognition Error: Bing Speech API Key not found

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Bing Speech:
1. Ø¨Ù‡ https://azure.microsoft.com Ø¨Ø±ÙˆÛŒØ¯
2. Bing Speech API ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
3. API Key Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set BING_KEY=your_key_here

ÛŒØ§ Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
                text = r.recognize_bing(audio, key=api_key)
            elif self.model_name == "speechrecognition_houndify":
                client_id = os.getenv("HOUNDIFY_CLIENT_ID")
                client_key = os.getenv("HOUNDIFY_CLIENT_KEY")
                if not client_id or not client_key:
                    return """SpeechRecognition Error: Houndify API Keys not found

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Houndify:
1. Ø¨Ù‡ https://www.houndify.com Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Client ID Ùˆ Client Key Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set HOUNDIFY_CLIENT_ID=your_client_id
   set HOUNDIFY_CLIENT_KEY=your_client_key

ÛŒØ§ Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
                text = r.recognize_houndify(audio, client_id=client_id, client_key=client_key)
            elif self.model_name == "speechrecognition_ibm":
                username = os.getenv("IBM_USERNAME")
                password = os.getenv("IBM_PASSWORD")
                if not username or not password:
                    return """SpeechRecognition Error: IBM Speech API Credentials not found

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² IBM Speech:
1. Ø¨Ù‡ https://www.ibm.com/cloud/watson-speech-to-text Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Username Ùˆ Password Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set IBM_USERNAME=your_username
   set IBM_PASSWORD=your_password

ÛŒØ§ Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
                text = r.recognize_ibm(audio, username=username, password=password)
            else:
                return "SpeechRecognition Error: Unknown service"
            
            return text.strip()
            
        except Exception as e:
            error_msg = str(e)
            if "key must be a string" in error_msg:
                return f"""SpeechRecognition Error: API Key Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ø¯

Ù…Ø´Ú©Ù„: Ú©Ù„ÛŒØ¯ API Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. API Key Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
3. Ø§Ø² Google Speech Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)

Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ:
set API_KEY_NAME=your_key_here
"""
            else:
                return f"SpeechRecognition Error: {error_msg}"
    
    def transcribe_with_silero(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Silero STT"""
        try:
            if not SILERO_AVAILABLE:
                return """Silero STT Error: Dependencies not installed

Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ Silero STT:

1. Ø§Ø¨ØªØ¯Ø§ omegaconf Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   pip install omegaconf

2. Ø³Ù¾Ø³ PyTorch Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   Ø¨Ø±Ø§ÛŒ CPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
   Ø¨Ø±Ø§ÛŒ GPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

3. Ø³Ù¾Ø³ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯

ÛŒØ§ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
â€¢ Google Speech (Ø¢Ù†Ù„Ø§ÛŒÙ†)
"""
            
            import torch
            import torchaudio
            import omegaconf
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø³Ø®Ù‡ PyTorch
            torch_version = torch.__version__
            
            # Ø¨Ø±Ø±Ø³ÛŒ cache Ù…Ø¯Ù„
            model_key = f"silero_{self.model_name}"
            if model_key in self.silero_models:
                model, decoder, utils = self.silero_models[model_key]
                if hasattr(self, 'download_status'):
                    self.download_status.emit("Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Silero STT Ù…ÙˆØ¬ÙˆØ¯")
            else:
                # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ØªØ±
                try:
                    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª torch.hub Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„
                    import os
                    os.environ['TORCH_HOME'] = str(Path.home() / '.cache' / 'torch')
                    
                    # ØªÙ†Ø¸ÛŒÙ… timeout Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
                    import socket
                    socket.setdefaulttimeout(60)
                    
                    # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¯Ø§Ù†Ù„ÙˆØ¯
                    if hasattr(self, 'download_status'):
                        self.download_status.emit("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Silero STT...")
                    
                    if self.model_name == "silero_stt_en":
                        model, decoder, utils = torch.hub.load(
                            repo_or_dir='snakers4/silero-models', 
                            model='silero_stt', 
                            language='en',
                            force_reload=False,
                            trust_repo=True,
                            verbose=True  # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ù†Ù„ÙˆØ¯
                        )
                    else:  # silero_stt_multilingual
                        model, decoder, utils = torch.hub.load(
                            repo_or_dir='snakers4/silero-models', 
                            model='silero_stt', 
                            language='multilingual',
                            force_reload=False,
                            trust_repo=True,
                            verbose=True  # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ù†Ù„ÙˆØ¯
                        )
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
                    self.silero_models[model_key] = (model, decoder, utils)
                    
                    # Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¯Ø§Ù†Ù„ÙˆØ¯
                    if hasattr(self, 'download_status'):
                        self.download_status.emit("Ù…Ø¯Ù„ Silero STT Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                
                except Exception as model_error:
                    error_msg = str(model_error)
                    
                    # Ø§Ú¯Ø± Ø®Ø·Ø§ Ø®Ø§Ù„ÛŒ Ø§Ø³ØªØŒ Ù¾ÛŒØ§Ù… Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù†Ù…Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯
                    if not error_msg or error_msg.strip() == "":
                        error_msg = "Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„"
                    
                    # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø®Ø·Ø§
                    if "SSL" in error_msg or "certificate" in error_msg.lower():
                        return f"""Silero STT Error: Ù…Ø´Ú©Ù„ SSL Certificate

Ù…Ø´Ú©Ù„: {error_msg}

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. VPN Ø±Ø§ Ø®Ø§Ù…ÙˆØ´ Ú©Ù†ÛŒØ¯ (Ø§Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯)
3. ÙØ§ÛŒØ±ÙˆØ§Ù„ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
4. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Google Speech (Ø¢Ù†Ù„Ø§ÛŒÙ†)
"""
                    elif "timeout" in error_msg.lower() or "connection" in error_msg.lower():
                        return f"""Silero STT Error: Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„

Ù…Ø´Ú©Ù„: {error_msg}

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ù…Ø¯Ù„ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯:
   - Ù¾ÙˆØ´Ù‡ ~/.cache/torch/hub Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯
   - Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯
3. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Google Speech (Ø¢Ù†Ù„Ø§ÛŒÙ†)
"""
                    else:
                        return f"""Silero STT Error: Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯

Ù…Ø´Ú©Ù„: {error_msg}

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ù…Ø¯Ù„ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯:
   - Ù¾ÙˆØ´Ù‡ ~/.cache/torch/hub Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯
   - Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯
3. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Google Speech (Ø¢Ù†Ù„Ø§ÛŒÙ†)
"""
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            try:
                audio, sample_rate = torchaudio.load(audio_file)
                
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ mono
                if audio.shape[0] > 1:
                    audio = torch.mean(audio, dim=0, keepdim=True)
                
                # ØªØ¨Ø¯ÛŒÙ„ sample rate Ø¨Ù‡ 16000 Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ø¯
                if sample_rate != 16000:
                    resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                    audio = resampler(audio)
                
                # ØªØ´Ø®ÛŒØµ
                with torch.no_grad():
                    text = decoder(model(audio[0]))
                
                return text.strip()
                
            except Exception as audio_error:
                return f"""Silero STT Error: Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ

Ù…Ø´Ú©Ù„: {str(audio_error)}

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. Ø§Ø² ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (WAV, MP3, M4A)
3. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Google Speech (Ø¢Ù†Ù„Ø§ÛŒÙ†)
"""
            
        except Exception as e:
            error_msg = str(e)
            if "No module named 'torch'" in error_msg:
                return """Silero STT Error: PyTorch not installed

Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ PyTorch:

1. Ø§Ø¨ØªØ¯Ø§ omegaconf Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   pip install omegaconf

2. Ø³Ù¾Ø³ PyTorch Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   Ø¨Ø±Ø§ÛŒ CPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
   Ø¨Ø±Ø§ÛŒ GPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

Ø³Ù¾Ø³ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯.
"""
            elif "No module named 'torchaudio'" in error_msg:
                return """Silero STT Error: TorchAudio not installed

Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ TorchAudio:

1. Ø§Ø¨ØªØ¯Ø§ omegaconf Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   pip install omegaconf

2. Ø³Ù¾Ø³ PyTorch Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   Ø¨Ø±Ø§ÛŒ CPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
   Ø¨Ø±Ø§ÛŒ GPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

Ø³Ù¾Ø³ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯.
"""
            elif "No module named 'omegaconf'" in error_msg:
                return """Silero STT Error: OmegaConf not installed

Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ OmegaConf:

1. Ø§Ø¨ØªØ¯Ø§ omegaconf Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   pip install omegaconf

2. Ø³Ù¾Ø³ PyTorch Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   Ø¨Ø±Ø§ÛŒ CPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
   Ø¨Ø±Ø§ÛŒ GPU: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

Ø³Ù¾Ø³ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯.
"""
            else:
                return f"""Silero STT Error: {error_msg}

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:
1. Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
2. ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
   pip install omegaconf
   pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
3. Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
   â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)
   â€¢ Google Speech (Ø¢Ù†Ù„Ø§ÛŒÙ†)
"""
    
    def transcribe_with_kaldi(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Kaldi"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Kaldi
            if not KALDI_AVAILABLE:
                return "Kaldi Error: kaldi-io not installed. Install with: pip install kaldi-io"
            
            # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡ Kaldi Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            if self.model_name == "kaldi_persian":
                # Ø¨Ø±Ø§ÛŒ Kaldi PersianØŒ Ø§Ø² ÛŒÚ© Ù…Ø¯Ù„ Ø³Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                # Ø§ÛŒÙ† ÛŒÚ© Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Kaldi Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø´ÙˆØ¯
                
                # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
                import soundfile as sf
                audio, sample_rate = sf.read(audio_file)
                
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ mono Ø§Ú¯Ø± stereo Ø¨Ø§Ø´Ø¯
                if len(audio.shape) > 1:
                    audio = audio.mean(axis=1)
                
                # ØªØ¨Ø¯ÛŒÙ„ sample rate Ø¨Ù‡ 16000
                if sample_rate != 16000:
                    from scipy import signal
                    audio = signal.resample(audio, int(len(audio) * 16000 / sample_rate))
                    sample_rate = 16000
                
                # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡ Kaldi
                # Ø§ÛŒÙ† ÛŒÚ© Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Kaldi Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø´ÙˆØ¯
                
                # Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±ØŒ Ø§Ø² ÛŒÚ© Ù…Ø¯Ù„ Ø³Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                # Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Kaldi ÙˆØ§Ù‚Ø¹ÛŒ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø·ÙˆÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
                duration = len(audio) / sample_rate
                
                # Ù¾ÛŒØ§Ù… Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
                result = f"Kaldi Persian: ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯ (Ù…Ø¯Øª: {duration:.2f} Ø«Ø§Ù†ÛŒÙ‡)\n"
                result += "Ù…Ø¯Ù„ Kaldi ÙØ§Ø±Ø³ÛŒ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.\n"
                result += "Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒØŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:\n"
                result += "â€¢ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)\n"
                result += "â€¢ Whisper Medium/Large (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)\n"
                result += "â€¢ Wav2Vec2 Persian (Hugging Face)"
                
                return result
                
            elif self.model_name == "kaldi_english":
                # Ø¨Ø±Ø§ÛŒ Kaldi English
                import soundfile as sf
                audio, sample_rate = sf.read(audio_file)
                
                if len(audio.shape) > 1:
                    audio = audio.mean(axis=1)
                
                if sample_rate != 16000:
                    from scipy import signal
                    audio = signal.resample(audio, int(len(audio) * 16000 / sample_rate))
                    sample_rate = 16000
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø·ÙˆÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
                duration = len(audio) / sample_rate
                
                # Ù¾ÛŒØ§Ù… Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
                result = f"Kaldi English: ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯ (Ù…Ø¯Øª: {duration:.2f} Ø«Ø§Ù†ÛŒÙ‡)\n"
                result += "Ù…Ø¯Ù„ Kaldi Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.\n"
                result += "Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:\n"
                result += "â€¢ Vosk Small/Large (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)\n"
                result += "â€¢ Whisper (Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡)\n"
                result += "â€¢ Silero STT English"
                
                return result
            else:
                return "Kaldi Error: Unknown Kaldi model"
            
        except ImportError as e:
            return f"Kaldi Error: Required dependencies not installed. Install with: pip install kaldi-io soundfile scipy"
        except Exception as e:
            return f"Kaldi Error: {str(e)}"
    
    def transcribe_with_iranian(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆÙ…ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ"""
        try:
            # Ø§ÛŒÙ† ÛŒÚ© Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª
            # Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ API key Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø§Ø³Øª
            
            if self.model_name == "iranian_arvan":
                return "Arvan Cloud Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key\nØ¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Arvan Cloud Speech API key Ø®ÙˆØ¯ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯."
            elif self.model_name == "iranian_fanap":
                return "Fanap Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key\nØ¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Fanap Speech API key Ø®ÙˆØ¯ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯."
            elif self.model_name == "iranian_parsijoo":
                return "Parsijoo Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key\nØ¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Parsijoo Speech API key Ø®ÙˆØ¯ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯."
            else:
                return "Iranian Service Error: Unknown service"
            
        except Exception as e:
            return f"Iranian Service Error: {str(e)}"


class VoiceApp(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Voice Analyzer")
        self.resize(900, 600)  # Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ú©Ø±Ø¯Ù† Ø³Ø§ÛŒØ² Ø§Ù¾
        self.layout = QVBoxLayout(self)

        self.label = QLabel("Select an audio file:")
        self.layout.addWidget(self.label)
        
        self.model_label = QLabel("Selected Model: vosk_persian (default)")
        self.model_label.setStyleSheet("color: blue; font-weight: bold;")
        self.layout.addWidget(self.model_label)

        # Ø¯Ú©Ù…Ù‡ Ù‡Ø§
        self.btn_select = QPushButton("Choose File")
        self.btn_select.setMinimumHeight(40)
        self.btn_select.clicked.connect(self.select_file)
        self.layout.addWidget(self.btn_select)

        self.btn_start_pause = QPushButton("Start / Pause")
        self.btn_start_pause.setMinimumHeight(40)
        self.btn_start_pause.clicked.connect(self.toggle_start_pause)
        self.layout.addWidget(self.btn_start_pause)

        self.btn_stop = QPushButton("Stop")
        self.btn_stop.setMinimumHeight(40)
        self.btn_stop.clicked.connect(self.stop_processing)
        self.layout.addWidget(self.btn_stop)

        self.btn_open_text = QPushButton("Open Text")
        self.btn_open_text.setMinimumHeight(40)
        self.btn_open_text.clicked.connect(self.open_text_file)
        self.layout.addWidget(self.btn_open_text)

        self.btn_manage_dict = QPushButton("Manage Dictionary")
        self.btn_manage_dict.setMinimumHeight(40)
        self.btn_manage_dict.clicked.connect(self.open_dict_manager)
        self.layout.addWidget(self.btn_manage_dict)

        # Ø¯Ú©Ù…Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
        self.btn_manage_models = QPushButton("ğŸ“¦ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡")
        self.btn_manage_models.setMinimumHeight(40)
        self.btn_manage_models.setStyleSheet("""
            QPushButton {
                background-color: #FF9800; 
                color: white; 
                font-weight: bold;
                border: none;
                border-radius: 6px;
            }
            QPushButton:hover {
                background-color: #F57C00;
            }
            QPushButton:pressed {
                background-color: #E65100;
            }
        """)
        self.btn_manage_models.clicked.connect(self.open_models_manager)
        self.layout.addWidget(self.btn_manage_models)

        # Help menu button
        self.btn_help = QPushButton("ğŸ“š Ø±Ø§Ù‡Ù†Ù…Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª")
        self.btn_help.setMinimumHeight(40)
        self.btn_help.setStyleSheet("""
            QPushButton {
                background-color: #607D8B; 
                color: white; 
                font-weight: bold;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #546E7A;
            }
            QPushButton:pressed {
                background-color: #455A64;
            }
        """)
        self.btn_help.clicked.connect(self.show_help_menu)
        self.layout.addWidget(self.btn_help)

        self.btn_download_models = QPushButton("Download Models")
        self.btn_download_models.setMinimumHeight(40)
        self.btn_download_models.setStyleSheet("""
            QPushButton {
                background-color: #ff6b35; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #e55a2b;
            }
            QPushButton:pressed {
                background-color: #cc4a1f;
            }
        """)
        self.btn_download_models.clicked.connect(self.show_download_models_dialog)
        self.layout.addWidget(self.btn_download_models)

        self.btn_change_model = QPushButton("Change Model")
        self.btn_change_model.setMinimumHeight(40)
        self.btn_change_model.setStyleSheet("""
            QPushButton {
                background-color: #9c27b0; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #8e24aa;
            }
            QPushButton:pressed {
                background-color: #7b1fa2;
            }
        """)
        self.btn_change_model.clicked.connect(self.change_model)
        self.layout.addWidget(self.btn_change_model)

        # Model status label - simple text without button styling
        self.model_status = QLabel("Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡")
        self.model_status.setStyleSheet("""
            color: #666666; 
            font-size: 14px;
            padding: 8px;
            background-color: transparent;
            border: none;
            outline: none;
        """)
        self.model_status.setAlignment(Qt.AlignCenter)
        self.model_status.setFocusPolicy(Qt.NoFocus)  # Remove focus ability
        self.layout.addWidget(self.model_status)
        
        # Progress bar for conversion
        self.progress = QProgressBar()
        self.progress.setStyleSheet("""
            QProgressBar {
                border: 2px solid #2196F3;
                border-radius: 8px;
                text-align: center;
                font-weight: bold;
                font-size: 14px;
                background-color: #2d2d2d;
                color: #ffffff;
            }
            QProgressBar::chunk {
                background: qlineargradient(x1: 0, y1: 0, x2: 1, y2: 0,
                    stop: 0 #4CAF50, stop: 1 #45a049);
                border-radius: 6px;
                margin: 1px;
            }
        """)
        self.layout.addWidget(self.progress)
        
        # Temporary notification label
        self.notification_label = QLabel("")
        self.notification_label.setVisible(False)
        self.notification_label.setStyleSheet("""
            color: #ffffff; 
            font-weight: bold; 
            font-size: 14px;
            padding: 12px;
            background-color: #424242;
            border: 2px solid #2196F3;
            border-radius: 8px;
        """)
        self.notification_label.setAlignment(Qt.AlignCenter)
        self.layout.addWidget(self.notification_label)

        self.scroll = QScrollArea()
        self.text_edit = QTextEdit()
        self.text_edit.setReadOnly(True)
        self.text_edit.setFontPointSize(14)  # Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø´Ø¯Ù† Ù…ØªÙ† Ù†Ù…Ø§ÛŒØ´ÛŒ
        self.scroll.setWidget(self.text_edit)
        self.scroll.setWidgetResizable(True)
        self.layout.addWidget(self.scroll)

        self.audio_path = None
        self.output_file = None
        self.thread = None
        self.dict_manager_window = None
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù…Ø¯Ù„ Ø¢Ø®Ø±
        config = ConfigManager.load_config()
        self.selected_model = config.get("selected_model", "vosk_persian")
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
        last_audio_path = config.get("last_audio_path", "")
        if last_audio_path and os.path.exists(last_audio_path):
            self.audio_path = last_audio_path
            self.label.setText(f"Last File: {last_audio_path}")
        
        # Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾Ù†Ø¬Ø±Ù‡
        window_geometry = config.get("window_geometry")
        if window_geometry:
            self.setGeometry(
                window_geometry.get("x", 100),
                window_geometry.get("y", 100),
                window_geometry.get("width", 900),
                window_geometry.get("height", 600)
            )
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„
        self.update_model_display()

    def update_model_display(self):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡"""
        model_info = ModelDownloader.DOWNLOADABLE_MODELS.get(self.selected_model, {})
        if model_info:
            model_name = model_info.get("name", self.selected_model)
            model_type = model_info.get("type", "Unknown")
            model_language = model_info.get("language", "Unknown")
            self.model_label.setText(f"Selected Model: {self.selected_model} ({model_type} - {model_language})")
        else:
            self.model_label.setText(f"Selected Model: {self.selected_model}")

    def select_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Audio File", "", 
            "Audio Files (*.mp3 *.wav *.m4a *.ogg *.flac)"
        )
        if file_path:
            self.audio_path = file_path
            self.label.setText(f"Selected: {file_path}")
            self.text_edit.clear()
            self.output_file = None
            self.thread = None  # Ø±ÛŒØ³Øª Ú©Ø±Ø¯Ù† thread Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø³ÛŒØ± Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            ConfigManager.update_audio_path(file_path)

    def start_transcription(self):
        if not self.audio_path:
            QMessageBox.warning(self, "Warning", "No audio file selected!")
            return

        # Ù†Ù…Ø§ÛŒØ´ dialog Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„
        dialog = ModelSelectionDialog(self)
        if dialog.exec() == QDialog.Accepted:
            self.selected_model = dialog.get_selected_model()
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
            ConfigManager.update_model(self.selected_model)
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„
            self.update_model_display()
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
            if not self.check_and_download_model():
                return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯ ÛŒØ§ Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ
            if self.selected_model in ["whisper_tiny", "whisper_base"]:
                reply = QMessageBox.question(
                    self, "Ù‡Ø´Ø¯Ø§Ø±", 
                    f"Ù…Ø¯Ù„ {self.selected_model} Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¶Ø¹ÛŒÙ Ø§Ø³Øª Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ØªØ§ÛŒØ¬ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¨Ø¯Ù‡Ø¯.\nØ¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Vosk
            if self.selected_model in ["vosk_small", "vosk_large"]:
                reply = QMessageBox.question(
                    self, "Ù‡Ø´Ø¯Ø§Ø± Ø²Ø¨Ø§Ù†", 
                    f"Ù…Ø¯Ù„ {self.selected_model} ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ùˆ ÙØ§Ø±Ø³ÛŒ Ø±Ø§ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯!\n\nØ¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø² 'Vosk Persian' Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\nØ¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
            paid_models = [
                "google_enhanced", "google_phone_call", "google_medical", "google_video",
                "azure_enhanced", "assemblyai_enhanced"
            ]
            if self.selected_model in paid_models:
                reply = QMessageBox.question(
                    self, "Ù‡Ø´Ø¯Ø§Ø± Ù‡Ø²ÛŒÙ†Ù‡", 
                    f"Ù…Ø¯Ù„ {self.selected_model} Ù¾ÙˆÙ„ÛŒ Ø§Ø³Øª Ùˆ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\nØ¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
            
            # Ø´Ø±ÙˆØ¹ Ú©Ø§Ù†ÙˆØ±Øª
            self.start_conversion()
        else:
            return  # Ú©Ø§Ø±Ø¨Ø± cancel Ú©Ø±Ø¯

    def check_and_download_model(self):
        """Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²"""
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ø¯Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if self.selected_model not in ModelDownloader.DOWNLOADABLE_MODELS:
            return True  # Ù…Ø¯Ù„ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø³Øª ÛŒØ§ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
        
        model_info = ModelDownloader.DOWNLOADABLE_MODELS[self.selected_model]
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
        if ModelDownloader.is_model_downloaded(self.selected_model):
            return True  # Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… ØªØ£ÛŒÛŒØ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯
        reply = QMessageBox.question(
            self, "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„", 
            f"Ù…Ø¯Ù„ {model_info['name']} ({model_info['size']}) Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.\n\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¢Ù† Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŸ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.Yes
        )
        
        if reply == QMessageBox.No:
            return False  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¯ÛŒØ§Ù„ÙˆÚ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
        download_dialog = ModelDownloadDialog(self.selected_model, model_info, self)
        download_dialog.start_download()  # Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯
        if download_dialog.exec() == QDialog.Accepted:
            # Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø¯Ø§Ù†Ù„ÙˆØ¯ØŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ø¨Ù¾Ø±Ø³ Ú©Ù‡ Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯ Ú©Ø§Ù†ÙˆØ±Øª Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†Ø¯
            reply = QMessageBox.question(
                self, "Ø´Ø±ÙˆØ¹ Ú©Ø§Ù†ÙˆØ±Øª", 
                f"Ù…Ø¯Ù„ {model_info['name']} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.\n\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ú©Ø§Ù†ÙˆØ±Øª Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯ØŸ",
                QMessageBox.Yes | QMessageBox.No,
                QMessageBox.Yes
            )
            return reply == QMessageBox.Yes
        else:
            return False  # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù„ØºÙˆ Ø´Ø¯

    def start_conversion(self):
        """Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù†ÙˆØ±Øª"""
        self.text_edit.clear()
        self.output_file = None
        self.thread = TranscribeThread(self.audio_path, self.selected_model)
        self.thread.progress.connect(self.progress.setValue)
        self.thread.finished.connect(self.display_result)
        self.thread.download_status.connect(self.show_notification)
        self.thread.start()

    def show_notification(self, message):
        """Ù†Ù…Ø§ÛŒØ´ Ù†ÙˆØªÛŒÙÛŒÚ©ÛŒØ´Ù† Ù…ÙˆÙ‚Øª"""
        from PySide6.QtCore import QTimer
        
        # Update model status when model is ready
        if "Ø¢Ù…Ø§Ø¯Ù‡" in message or "Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯" in message:
            self.model_status.setText("âœ… Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            self.model_status.setStyleSheet("""
                color: #4CAF50; 
                font-size: 14px;
                padding: 8px;
                background-color: transparent;
                border: none;
                outline: none;
            """)
        
        # Show temporary notification
        self.notification_label.setText(f"ğŸ“¥ {message}")
        self.notification_label.setVisible(True)
        
        # Auto-hide after 3 seconds
        QTimer.singleShot(3000, self.hide_notification)
    
    def hide_notification(self):
        """Ù…Ø®ÙÛŒ Ú©Ø±Ø¯Ù† Ù†ÙˆØªÛŒÙÛŒÚ©ÛŒØ´Ù†"""
        self.notification_label.setVisible(False)

    def display_result(self, text):
        # Add model information below the converted text
        model_info = f"\n\n---\nÚ©Ø§Ù†ÙˆØ±Øª Ø´Ø¯Ù‡ Ø¨Ø§ Ù…Ø¯Ù„: {self.selected_model}"
        full_text = text + model_info
        
        self.text_edit.setPlainText(full_text)
        save_path, _ = QFileDialog.getSaveFileName(
            self, "Save Text", "", "Text Files (*.txt)"
        )
        if save_path:
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(full_text)
            self.output_file = save_path
        
        # Reset thread to allow re-conversion
        self.thread = None

    def open_text_file(self):
        if self.output_file and os.path.exists(self.output_file):
            webbrowser.open(self.output_file)
        else:
            QMessageBox.warning(self, "Warning", "No saved text file to open!")

    def toggle_start_pause(self):
        if not self.audio_path:
            QMessageBox.warning(self, "Warning", "No audio file selected!")
            return

        if not self.thread or not self.thread.isRunning():
            # Allow re-conversion of the same file
            self.start_transcription()
        else:
            QMessageBox.information(self, "Info", "Conversion is already in progress. Please wait for it to complete.")

    def stop_processing(self):
        if self.thread and self.thread.isRunning():
            QMessageBox.information(self, "Info", "Stop clicked (future implementation).")

    def open_dict_manager(self):
        if not self.dict_manager_window:
            self.dict_manager_window = DictManager()
        self.dict_manager_window.show()
        self.dict_manager_window.raise_()
        self.dict_manager_window.activateWindow()

    def open_models_manager(self):
        """Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ù¾Ù†Ø¬Ø±Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡"""
        dialog = DownloadedModelsManager(self)
        dialog.exec()

    def change_model(self):
        """ØªØºÛŒÛŒØ± Ù…Ø¯Ù„ Ø¨Ø¯ÙˆÙ† Ø´Ø±ÙˆØ¹ transcription"""
        dialog = ModelSelectionDialog(self)
        if dialog.exec() == QDialog.Accepted:
            self.selected_model = dialog.get_selected_model()
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
            ConfigManager.update_model(self.selected_model)
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„
            self.update_model_display()
            
            QMessageBox.information(self, "Model Changed", f"Model changed to: {self.selected_model}")

    def closeEvent(self, event):
        """Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø³ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        # Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Ø¹ÛŒØª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾Ù†Ø¬Ø±Ù‡
        geometry = {
            "x": self.x(),
            "y": self.y(),
            "width": self.width(),
            "height": self.height()
        }
        ConfigManager.update_window_geometry(geometry)
        event.accept()

    def show_help_menu(self):
        """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ Ø±Ø§Ù‡Ù†Ù…Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QPushButton, QHBoxLayout, QLabel, QScrollArea, QWidget
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("ğŸ“š Ø±Ø§Ù‡Ù†Ù…Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª")
        dialog.setModal(True)
        dialog.resize(800, 600)
        
        layout = QVBoxLayout(dialog)
        
        # Title
        title_label = QLabel("Ø±Ø§Ù‡Ù†Ù…Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ù†Ø§Ù…Ù‡")
        title_label.setStyleSheet("font-weight: bold; font-size: 18px; color: #1976D2; padding: 10px;")
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # Scroll area for buttons
        scroll_area = QScrollArea()
        scroll_widget = QWidget()
        scroll_layout = QVBoxLayout(scroll_widget)
        
        # Setup guides section
        setup_label = QLabel("ğŸ”§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ø¯Ù„â€ŒÙ‡Ø§:")
        setup_label.setStyleSheet("font-weight: bold; font-size: 14px; color: #424242; padding: 5px;")
        scroll_layout.addWidget(setup_label)
        
        # Google Setup
        btn_google_setup = QPushButton("Google Speech Setup Guide")
        btn_google_setup.setMinimumHeight(40)
        btn_google_setup.setStyleSheet("""
            QPushButton {
                background-color: #4285f4; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #3367d6;
            }
            QPushButton:pressed {
                background-color: #2c5aa0;
            }
        """)
        btn_google_setup.clicked.connect(lambda: (dialog.accept(), self.show_google_setup_guide()))
        scroll_layout.addWidget(btn_google_setup)
        
        # Hugging Face Setup
        btn_huggingface_setup = QPushButton("Hugging Face Setup Guide")
        btn_huggingface_setup.setMinimumHeight(40)
        btn_huggingface_setup.setStyleSheet("""
            QPushButton {
                background-color: #ff6b35; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #e55a2b;
            }
            QPushButton:pressed {
                background-color: #cc4a1f;
            }
        """)
        btn_huggingface_setup.clicked.connect(lambda: (dialog.accept(), self.show_huggingface_setup_guide()))
        scroll_layout.addWidget(btn_huggingface_setup)
        
        # SpeechRecognition Setup
        btn_speechrecognition_setup = QPushButton("SpeechRecognition Setup Guide")
        btn_speechrecognition_setup.setMinimumHeight(40)
        btn_speechrecognition_setup.setStyleSheet("""
            QPushButton {
                background-color: #2196F3; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #1976D2;
            }
            QPushButton:pressed {
                background-color: #1565C0;
            }
        """)
        btn_speechrecognition_setup.clicked.connect(lambda: (dialog.accept(), self.show_speechrecognition_setup_guide()))
        scroll_layout.addWidget(btn_speechrecognition_setup)
        
        # PyTorch Install Guide
        btn_install_pytorch = QPushButton("Ù†ØµØ¨ PyTorch (Ø¨Ø±Ø§ÛŒ Silero)")
        btn_install_pytorch.setMinimumHeight(40)
        btn_install_pytorch.setStyleSheet("""
            QPushButton {
                background-color: #9C27B0; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #8E24AA;
            }
            QPushButton:pressed {
                background-color: #7B1FA2;
            }
        """)
        btn_install_pytorch.clicked.connect(lambda: (dialog.accept(), self.show_pytorch_install_guide()))
        scroll_layout.addWidget(btn_install_pytorch)
        
        # Test and maintenance section
        test_label = QLabel("ğŸ§ª ØªØ³Øª Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ:")
        test_label.setStyleSheet("font-weight: bold; font-size: 14px; color: #424242; padding: 5px; margin-top: 10px;")
        scroll_layout.addWidget(test_label)
        
        # Test Silero
        btn_test_silero = QPushButton("ØªØ³Øª Silero STT")
        btn_test_silero.setMinimumHeight(40)
        btn_test_silero.setStyleSheet("""
            QPushButton {
                background-color: #FF5722; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #E64A19;
            }
            QPushButton:pressed {
                background-color: #D84315;
            }
        """)
        btn_test_silero.clicked.connect(lambda: (dialog.accept(), self.test_silero_stt()))
        scroll_layout.addWidget(btn_test_silero)
        
        # Clear Silero Cache
        btn_clear_silero_cache = QPushButton("Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Cache Silero")
        btn_clear_silero_cache.setMinimumHeight(40)
        btn_clear_silero_cache.setStyleSheet("""
            QPushButton {
                background-color: #795548; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #6D4C41;
            }
            QPushButton:pressed {
                background-color: #5D4037;
            }
        """)
        btn_clear_silero_cache.clicked.connect(lambda: (dialog.accept(), self.clear_silero_cache()))
        scroll_layout.addWidget(btn_clear_silero_cache)
        
        # Add stretch to push buttons to top
        scroll_layout.addStretch()
        
        scroll_area.setWidget(scroll_widget)
        scroll_area.setWidgetResizable(True)
        layout.addWidget(scroll_area)
        
        # Close button
        close_layout = QHBoxLayout()
        close_layout.addStretch()
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.setMinimumHeight(40)
        close_btn.setStyleSheet("""
            QPushButton {
                background-color: #607D8B; 
                color: white;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #546E7A;
            }
            QPushButton:pressed {
                background-color: #455A64;
            }
        """)
        close_btn.clicked.connect(dialog.accept)
        close_layout.addWidget(close_btn)
        close_layout.addStretch()
        layout.addLayout(close_layout)
        
        dialog.exec()

    def show_google_setup_guide(self):
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QTextEdit, QPushButton, QHBoxLayout
        from PySide6.QtCore import Qt
        from PySide6.QtGui import QTextCursor
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Google Speech")
        dialog.setModal(True)
        dialog.resize(600, 500)
        
        layout = QVBoxLayout(dialog)
        
        # Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        text_edit.setHtml("""
        <h2>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Google Speech-to-Text</h2>
        
        <h3>ğŸ”§ Ù…Ø±Ø§Ø­Ù„ ØªÙ†Ø¸ÛŒÙ…:</h3>
        
        <h4>1ï¸âƒ£ Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡ Google Cloud:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://console.cloud.google.com">Google Cloud Console</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Ø±ÙˆÛŒ "New Project" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ Ùˆ "Create" Ø¨Ø²Ù†ÛŒØ¯</p>
        
        <h4>2ï¸âƒ£ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ API:</h4>
        <p>â€¢ Ø¯Ø± Ù…Ù†ÙˆØŒ "APIs & Services" > "Library" Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ "Speech-to-Text API" Ø±Ø§ Ø¬Ø³ØªØ¬Ùˆ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ø±ÙˆÛŒ Ø¢Ù† Ú©Ù„ÛŒÚ© Ú©Ø±Ø¯Ù‡ Ùˆ "Enable" Ø¨Ø²Ù†ÛŒØ¯</p>
        
        <h4>3ï¸âƒ£ Ø§ÛŒØ¬Ø§Ø¯ Service Account:</h4>
        <p>â€¢ "APIs & Services" > "Credentials" Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ "Create Credentials" > "Service Account" Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù†Ø§Ù… Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Role: "Cloud Speech Client" Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        
        <h4>4ï¸âƒ£ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù„ÛŒØ¯ JSON:</h4>
        <p>â€¢ Ø±ÙˆÛŒ Service Account Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ ØªØ¨ "Keys" > "Add Key" > "Create new key"</p>
        <p>â€¢ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯</p>
        
        <h4>5ï¸âƒ£ ØªÙ†Ø¸ÛŒÙ… Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ:</h4>
        <p>â€¢ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ø§Ù…Ù† Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯</p>
        <p>â€¢ Ø¯Ø± Command Prompt Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>set GOOGLE_APPLICATION_CREDENTIALS=C:\\path\\to\\your\\key.json</code></p>
        
        <h3>ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:</h3>
        <p>â€¢ Google Speech 60 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ù…Ø§Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª</p>
        <p>â€¢ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨ÛŒØ´ØªØ±ØŒ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯</p>
        <p>â€¢ Whisper Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ† Ø§Ø³Øª</p>
        
        <h3>ğŸ”— Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯:</h3>
        <p>â€¢ <a href="https://console.cloud.google.com">Google Cloud Console</a></p>
        <p>â€¢ <a href="https://cloud.google.com/speech-to-text/docs">Ù…Ø³ØªÙ†Ø¯Ø§Øª Speech-to-Text</a></p>
        <p>â€¢ <a href="https://cloud.google.com/docs/authentication/external/set-up-adc">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Authentication</a></p>
        """)
        
        layout.addWidget(text_edit)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        open_console_btn = QPushButton("Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Google Cloud Console")
        open_console_btn.setStyleSheet("background-color: #4285f4; color: white; padding: 8px;")
        open_console_btn.clicked.connect(lambda: webbrowser.open("https://console.cloud.google.com"))
        
        open_docs_btn = QPushButton("Ù…Ø³ØªÙ†Ø¯Ø§Øª Speech-to-Text")
        open_docs_btn.setStyleSheet("background-color: #34a853; color: white; padding: 8px;")
        open_docs_btn.clicked.connect(lambda: webbrowser.open("https://cloud.google.com/speech-to-text/docs"))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(open_console_btn)
        button_layout.addWidget(open_docs_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    def show_download_models_dialog(self):
        """Ù†Ù…Ø§ÛŒØ´ dialog Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QListWidget, QPushButton, QHBoxLayout, QLabel, QTabWidget, QWidget
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Speech-to-Text")
        dialog.setModal(True)
        dialog.resize(700, 500)
        
        layout = QVBoxLayout(dialog)
        
        # ØªÙˆØ¶ÛŒØ­Ø§Øª
        info_label = QLabel("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ†):")
        layout.addWidget(info_label)
        
        # Tab widget Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        tab_widget = QTabWidget()
        
        # Tab Vosk
        vosk_tab = QWidget()
        vosk_layout = QVBoxLayout(vosk_tab)
        vosk_list = QListWidget()
        
        for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
            if model_info["type"] == "Vosk":
                status = "âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡" if ModelDownloader.is_model_downloaded(model_id) else "âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡"
                item_text = f"{model_info['name']} ({model_info['size']}) - {model_info['warning']} - {status}"
                vosk_list.addItem(item_text)
        
        vosk_layout.addWidget(vosk_list)
        tab_widget.addTab(vosk_tab, "Vosk Models")
        
        # Tab Whisper
        whisper_tab = QWidget()
        whisper_layout = QVBoxLayout(whisper_tab)
        whisper_list = QListWidget()
        
        for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
            if model_info["type"] == "Whisper":
                status = "âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡" if ModelDownloader.is_model_downloaded(model_id) else "âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡"
                item_text = f"{model_info['name']} ({model_info['size']}) - {model_info['warning']} - {status}"
                whisper_list.addItem(item_text)
        
        whisper_layout.addWidget(whisper_list)
        tab_widget.addTab(whisper_tab, "Whisper Models")
        
        # Tab Hugging Face
        hf_tab = QWidget()
        hf_layout = QVBoxLayout(hf_tab)
        hf_list = QListWidget()
        
        for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
            if model_info["type"] == "HuggingFace":
                status = "âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡" if ModelDownloader.is_model_downloaded(model_id) else "âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡"
                item_text = f"{model_info['name']} ({model_info['size']}) - {model_info['warning']} - {status}"
                hf_list.addItem(item_text)
        
        hf_layout.addWidget(hf_list)
        tab_widget.addTab(hf_tab, "Hugging Face Models")
        
        # Tab SpeechRecognition
        sr_tab = QWidget()
        sr_layout = QVBoxLayout(sr_tab)
        sr_list = QListWidget()
        
        for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
            if model_info["type"] == "SpeechRecognition":
                status = "âœ… Ø¢Ù…Ø§Ø¯Ù‡" if True else "âŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…"
                item_text = f"{model_info['name']} ({model_info['size']}) - {model_info['warning']} - {status}"
                sr_list.addItem(item_text)
        
        sr_layout.addWidget(sr_list)
        tab_widget.addTab(sr_tab, "SpeechRecognition")
        
        # Tab Silero
        silero_tab = QWidget()
        silero_layout = QVBoxLayout(silero_tab)
        silero_list = QListWidget()
        
        for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
            if model_info["type"] == "Silero":
                status = "âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡" if ModelDownloader.is_model_downloaded(model_id) else "âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡"
                item_text = f"{model_info['name']} ({model_info['size']}) - {model_info['warning']} - {status}"
                silero_list.addItem(item_text)
        
        silero_layout.addWidget(silero_list)
        tab_widget.addTab(silero_tab, "Silero STT")
        
        
        layout.addWidget(tab_widget)
        
        # Ø°Ø®ÛŒØ±Ù‡ reference Ù‡Ø§
        dialog.vosk_list = vosk_list
        dialog.whisper_list = whisper_list
        dialog.hf_list = hf_list
        dialog.sr_list = sr_list
        dialog.silero_list = silero_list
        dialog.tab_widget = tab_widget
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        download_btn = QPushButton("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡")
        download_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        download_btn.clicked.connect(lambda: self.download_selected_model(dialog))
        
        download_all_btn = QPushButton("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk")
        download_all_btn.setStyleSheet("background-color: #2196F3; color: white; padding: 8px;")
        download_all_btn.clicked.connect(lambda: self.download_all_vosk_models(dialog))
        
        download_whisper_btn = QPushButton("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper")
        download_whisper_btn.setStyleSheet("background-color: #FF9800; color: white; padding: 8px;")
        download_whisper_btn.clicked.connect(lambda: self.download_all_whisper_models(dialog))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(download_btn)
        button_layout.addWidget(download_all_btn)
        button_layout.addWidget(download_whisper_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    def show_huggingface_setup_guide(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Hugging Face"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QTextEdit, QPushButton, QHBoxLayout
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Hugging Face")
        dialog.setModal(True)
        dialog.resize(600, 500)
        
        layout = QVBoxLayout(dialog)
        
        # Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        text_edit.setHtml("""
        <h2>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Hugging Face</h2>
        
        <h3>ğŸ”§ Ù…Ø±Ø§Ø­Ù„ ØªÙ†Ø¸ÛŒÙ…:</h3>
        
        <h4>1ï¸âƒ£ Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://huggingface.co">Hugging Face</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Ø±ÙˆÛŒ "Sign Up" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø³Ø§Ø²ÛŒØ¯</p>
        
        <h4>2ï¸âƒ£ Ù†ØµØ¨ Hugging Face CLI:</h4>
        <p>â€¢ Ø¯Ø± Command Prompt Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>pip install huggingface_hub</code></p>
        
        <h4>3ï¸âƒ£ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ:</h4>
        <p>â€¢ Ø¯Ø± Command Prompt Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>huggingface-cli login</code></p>
        <p>â€¢ Token Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯</p>
        
        <h4>4ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Token:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://huggingface.co/settings/tokens">Settings > Tokens</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ "New token" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù†Ø§Ù… Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Token Ø±Ø§ Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯</p>
        
        <h3>ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:</h3>
        <p>â€¢ Ø¨Ø±Ø®ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ø¯Ø§Ø±Ù†Ø¯</p>
        <p>â€¢ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨Ø§Ø´Ù†Ø¯</p>
        <p>â€¢ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</p>
        
        <h3>ğŸ”— Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯:</h3>
        <p>â€¢ <a href="https://huggingface.co">Hugging Face</a></p>
        <p>â€¢ <a href="https://huggingface.co/models">Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯</a></p>
        <p>â€¢ <a href="https://huggingface.co/docs/hub/quick-start">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø³Ø±ÛŒØ¹</a></p>
        """)
        
        layout.addWidget(text_edit)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        open_hf_btn = QPushButton("Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Hugging Face")
        open_hf_btn.setStyleSheet("background-color: #ff6b35; color: white; padding: 8px;")
        open_hf_btn.clicked.connect(lambda: webbrowser.open("https://huggingface.co"))
        
        open_tokens_btn = QPushButton("Ù…Ø¯ÛŒØ±ÛŒØª Tokens")
        open_tokens_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        open_tokens_btn.clicked.connect(lambda: webbrowser.open("https://huggingface.co/settings/tokens"))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(open_hf_btn)
        button_layout.addWidget(open_tokens_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    def show_speechrecognition_setup_guide(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… SpeechRecognition"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QTextEdit, QPushButton, QHBoxLayout
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… SpeechRecognition")
        dialog.setModal(True)
        dialog.resize(700, 600)
        
        layout = QVBoxLayout(dialog)
        
        # Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        text_edit.setHtml("""
        <h2>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… SpeechRecognition</h2>
        
        <h3>ğŸ”§ ØªÙ†Ø¸ÛŒÙ… API Keys:</h3>
        
        <h4>1ï¸âƒ£ Google Speech (Ø±Ø§ÛŒÚ¯Ø§Ù† - Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ):</h4>
        <p>â€¢ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ API Key Ù†Ø¯Ø§Ø±Ø¯</p>
        <p>â€¢ 60 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ù…Ø§Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù†</p>
        <p>â€¢ Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ</p>
        
        <h4>2ï¸âƒ£ Wit.ai:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://wit.ai">Wit.ai</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯</p>
        <p>â€¢ API Key Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:</p>
        <p><code>set WIT_AI_KEY=your_key_here</code></p>
        
        <h4>3ï¸âƒ£ Azure Speech:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://portal.azure.com">Azure Portal</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Cognitive Services > Speech Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ API Key Ùˆ Region Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:</p>
        <p><code>set AZURE_SPEECH_KEY=your_key_here</code></p>
        <p><code>set AZURE_SPEECH_REGION=your_region_here</code></p>
        
        <h4>4ï¸âƒ£ Bing Speech:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://azure.microsoft.com">Azure</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Bing Speech API ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ API Key Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:</p>
        <p><code>set BING_KEY=your_key_here</code></p>
        
        <h4>5ï¸âƒ£ Houndify:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://www.houndify.com">Houndify</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯</p>
        <p>â€¢ Client ID Ùˆ Client Key Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:</p>
        <p><code>set HOUNDIFY_CLIENT_ID=your_client_id</code></p>
        <p><code>set HOUNDIFY_CLIENT_KEY=your_client_key</code></p>
        
        <h4>6ï¸âƒ£ IBM Speech:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://www.ibm.com/cloud/watson-speech-to-text">IBM Watson</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯</p>
        <p>â€¢ Username Ùˆ Password Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:</p>
        <p><code>set IBM_USERNAME=your_username</code></p>
        <p><code>set IBM_PASSWORD=your_password</code></p>
        
        <h3>ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:</h3>
        <p>â€¢ Google Speech Ø¨Ù‡ØªØ±ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª</p>
        <p>â€¢ CMU Sphinx Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¢ÙÙ„Ø§ÛŒÙ† Ø§Ø³Øª (ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)</p>
        <p>â€¢ Ø³Ø§ÛŒØ± Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key Ø¯Ø§Ø±Ù†Ø¯</p>
        <p>â€¢ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø±Ø§ Ø¯Ø± Command Prompt ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯</p>
        
        <h3>ğŸ”— Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯:</h3>
        <p>â€¢ <a href="https://wit.ai">Wit.ai</a></p>
        <p>â€¢ <a href="https://portal.azure.com">Azure Portal</a></p>
        <p>â€¢ <a href="https://www.houndify.com">Houndify</a></p>
        <p>â€¢ <a href="https://www.ibm.com/cloud/watson-speech-to-text">IBM Watson</a></p>
        """)
        
        layout.addWidget(text_edit)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        open_wit_btn = QPushButton("Wit.ai")
        open_wit_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        open_wit_btn.clicked.connect(lambda: webbrowser.open("https://wit.ai"))
        
        open_azure_btn = QPushButton("Azure Portal")
        open_azure_btn.setStyleSheet("background-color: #2196F3; color: white; padding: 8px;")
        open_azure_btn.clicked.connect(lambda: webbrowser.open("https://portal.azure.com"))
        
        open_houndify_btn = QPushButton("Houndify")
        open_houndify_btn.setStyleSheet("background-color: #FF9800; color: white; padding: 8px;")
        open_houndify_btn.clicked.connect(lambda: webbrowser.open("https://www.houndify.com"))
        
        open_ibm_btn = QPushButton("IBM Watson")
        open_ibm_btn.setStyleSheet("background-color: #9C27B0; color: white; padding: 8px;")
        open_ibm_btn.clicked.connect(lambda: webbrowser.open("https://www.ibm.com/cloud/watson-speech-to-text"))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(open_wit_btn)
        button_layout.addWidget(open_azure_btn)
        button_layout.addWidget(open_houndify_btn)
        button_layout.addWidget(open_ibm_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    
    def show_pytorch_install_guide(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†ØµØ¨ PyTorch"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QTextEdit, QPushButton, QHBoxLayout
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†ØµØ¨ PyTorch Ø¨Ø±Ø§ÛŒ Silero STT")
        dialog.setModal(True)
        dialog.resize(700, 600)
        
        layout = QVBoxLayout(dialog)
        
        # Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        text_edit.setHtml("""
        <h2>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†ØµØ¨ PyTorch Ø¨Ø±Ø§ÛŒ Silero STT</h2>
        
        <h3>ğŸ”§ Ù…Ø±Ø§Ø­Ù„ Ù†ØµØ¨:</h3>
        
        <h4>1ï¸âƒ£ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÛŒØ³ØªÙ…:</h4>
        <p>Ø§Ø¨ØªØ¯Ø§ Ù†ÙˆØ¹ Ø³ÛŒØ³ØªÙ… Ø®ÙˆØ¯ Ø±Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ù‡ÛŒØ¯:</p>
        <p>â€¢ <strong>CPU:</strong> Ø§Ú¯Ø± Ú©Ø§Ø±Øª Ú¯Ø±Ø§ÙÛŒÚ© Ù†Ø¯Ø§Ø±ÛŒØ¯ ÛŒØ§ Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø² GPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ <strong>GPU:</strong> Ø§Ú¯Ø± Ú©Ø§Ø±Øª Ú¯Ø±Ø§ÙÛŒÚ© NVIDIA Ø¯Ø§Ø±ÛŒØ¯ Ùˆ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</p>
        
        <h4>2ï¸âƒ£ Ù†ØµØ¨ omegaconf:</h4>
        <p>Ø§Ø¨ØªØ¯Ø§ omegaconf Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:</p>
        <p><code>pip install omegaconf</code></p>
        
        <h4>3ï¸âƒ£ Ù†ØµØ¨ Ø¨Ø±Ø§ÛŒ CPU:</h4>
        <p>Ø¯Ø± Command Prompt ÛŒØ§ Terminal Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu</code></p>
        
        <h4>4ï¸âƒ£ Ù†ØµØ¨ Ø¨Ø±Ø§ÛŒ GPU (CUDA 11.8):</h4>
        <p>Ø¯Ø± Command Prompt ÛŒØ§ Terminal Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118</code></p>
        
        <h4>5ï¸âƒ£ Ù†ØµØ¨ Ø¨Ø±Ø§ÛŒ GPU (CUDA 12.1):</h4>
        <p>Ø¯Ø± Command Prompt ÛŒØ§ Terminal Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121</code></p>
        
        <h4>6ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ Ù†ØµØ¨:</h4>
        <p>Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù†ØµØ¨ØŒ Ø¯Ø± Python Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>import torch</code></p>
        <p><code>print(torch.__version__)</code></p>
        <p><code>print(torch.cuda.is_available())  # Ø¨Ø±Ø§ÛŒ GPU</code></p>
        
        <h3>ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:</h3>
        <p>â€¢ Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ PyTorch Ù†ØµØ¨ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯ØŒ Ø§Ø¨ØªØ¯Ø§ Ø¢Ù† Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯:</p>
        <p><code>pip uninstall torch torchaudio</code></p>
        <p>â€¢ Ø³Ù¾Ø³ Ø¯Ø³ØªÙˆØ± Ù†ØµØ¨ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù¾Ø³ Ø§Ø² Ù†ØµØ¨ØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯</p>
        
        <h3>ğŸš¨ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬:</h3>
        <p>â€¢ <strong>Ø®Ø·Ø§ÛŒ "No module named 'torch'":</strong> PyTorch Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª</p>
        <p>â€¢ <strong>Ø®Ø·Ø§ÛŒ "No module named 'torchaudio'":</strong> TorchAudio Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª</p>
        <p>â€¢ <strong>Ø®Ø·Ø§ÛŒ CUDA:</strong> Ù†Ø³Ø®Ù‡ CUDA Ø¨Ø§ PyTorch Ø³Ø§Ø²Ú¯Ø§Ø± Ù†ÛŒØ³Øª</p>
        
        <h3>ğŸ”— Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯:</h3>
        <p>â€¢ <a href="https://pytorch.org/get-started/locally/">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø±Ø³Ù…ÛŒ PyTorch</a></p>
        <p>â€¢ <a href="https://pytorch.org/get-started/previous-versions/">Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ PyTorch</a></p>
        <p>â€¢ <a href="https://github.com/snakers4/silero-models">Silero Models</a></p>
        """)
        
        layout.addWidget(text_edit)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        copy_cpu_btn = QPushButton("Ú©Ù¾ÛŒ Ø¯Ø³ØªÙˆØ± CPU")
        copy_cpu_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        copy_omegaconf_btn = QPushButton("Ú©Ù¾ÛŒ Ø¯Ø³ØªÙˆØ± omegaconf")
        copy_omegaconf_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        copy_omegaconf_btn.clicked.connect(lambda: self.copy_to_clipboard("pip install omegaconf"))
        
        copy_cpu_btn = QPushButton("Ú©Ù¾ÛŒ Ø¯Ø³ØªÙˆØ± CPU")
        copy_cpu_btn.setStyleSheet("background-color: #2196F3; color: white; padding: 8px;")
        copy_cpu_btn.clicked.connect(lambda: self.copy_to_clipboard("pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu"))
        
        copy_gpu_btn = QPushButton("Ú©Ù¾ÛŒ Ø¯Ø³ØªÙˆØ± GPU")
        copy_gpu_btn.setStyleSheet("background-color: #FF9800; color: white; padding: 8px;")
        copy_gpu_btn.clicked.connect(lambda: self.copy_to_clipboard("pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118"))
        
        open_pytorch_btn = QPushButton("Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† PyTorch")
        open_pytorch_btn.setStyleSheet("background-color: #2196F3; color: white; padding: 8px;")
        open_pytorch_btn.clicked.connect(lambda: webbrowser.open("https://pytorch.org/get-started/locally/"))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(copy_omegaconf_btn)
        button_layout.addWidget(copy_cpu_btn)
        button_layout.addWidget(copy_gpu_btn)
        button_layout.addWidget(open_pytorch_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    def copy_to_clipboard(self, text):
        """Ú©Ù¾ÛŒ Ù…ØªÙ† Ø¨Ù‡ Ú©Ù„ÛŒÙ¾â€ŒØ¨ÙˆØ±Ø¯"""
        from PySide6.QtWidgets import QApplication
        clipboard = QApplication.clipboard()
        clipboard.setText(text)
        QMessageBox.information(self, "Ú©Ù¾ÛŒ Ø´Ø¯", f"Ø¯Ø³ØªÙˆØ± Ú©Ù¾ÛŒ Ø´Ø¯:\n{text}")
    
    def test_silero_stt(self):
        """ØªØ³Øª Silero STT"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QTextEdit, QPushButton, QHBoxLayout, QLabel
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("ØªØ³Øª Silero STT")
        dialog.setModal(True)
        dialog.resize(600, 400)
        
        layout = QVBoxLayout(dialog)
        
        # Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§
        info_label = QLabel("ØªØ³Øª ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Silero STT")
        info_label.setStyleSheet("font-weight: bold; font-size: 16px; color: #1976D2; padding: 10px;")
        layout.addWidget(info_label)
        
        # Ù†ØªØ§ÛŒØ¬ ØªØ³Øª
        results_text = QTextEdit()
        results_text.setReadOnly(True)
        results_text.setMaximumHeight(200)
        layout.addWidget(results_text)
        
        def run_test():
            results = []
            
            # ØªØ³Øª omegaconf
            try:
                import omegaconf
                results.append("âœ… omegaconf: Ù†ØµØ¨ Ø´Ø¯Ù‡")
            except ImportError:
                results.append("âŒ omegaconf: Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡")
            
            # ØªØ³Øª torch
            try:
                import torch
                results.append(f"âœ… torch: Ù†ØµØ¨ Ø´Ø¯Ù‡ (Ù†Ø³Ø®Ù‡ {torch.__version__})")
            except ImportError:
                results.append("âŒ torch: Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡")
            
            # ØªØ³Øª torchaudio
            try:
                import torchaudio
                results.append(f"âœ… torchaudio: Ù†ØµØ¨ Ø´Ø¯Ù‡ (Ù†Ø³Ø®Ù‡ {torchaudio.__version__})")
            except ImportError:
                results.append("âŒ torchaudio: Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡")
            
            # ØªØ³Øª cache
            cache_path = Path.home() / '.cache' / 'torch' / 'hub'
            if cache_path.exists():
                results.append(f"âœ… Cache Ù…ÙˆØ¬ÙˆØ¯: {cache_path}")
                # Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ cache
                try:
                    cache_files = list(cache_path.rglob("*"))
                    results.append(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ cache: {len(cache_files)}")
                except:
                    results.append("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† cache")
            else:
                results.append(f"âŒ Cache Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª: {cache_path}")
            
            # ØªØ³Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
            try:
                import torch
                import omegaconf
                
                results.append("\nğŸ”„ ØªØ³Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„...")
                
                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„
                import os
                os.environ['TORCH_HOME'] = str(Path.home() / '.cache' / 'torch')
                import socket
                socket.setdefaulttimeout(30)
                
                # ØªØ³Øª Ù…Ø¯Ù„ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                try:
                    model, decoder, utils = torch.hub.load(
                        repo_or_dir='snakers4/silero-models', 
                        model='silero_stt', 
                        language='en',
                        force_reload=False,
                        trust_repo=True,
                        verbose=False
                    )
                    results.append("âœ… Ù…Ø¯Ù„ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆÙÙ‚")
                except Exception as e:
                    results.append(f"âŒ Ù…Ø¯Ù„ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ: Ø®Ø·Ø§ - {str(e)}")
                
                # ØªØ³Øª Ù…Ø¯Ù„ Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡
                try:
                    model, decoder, utils = torch.hub.load(
                        repo_or_dir='snakers4/silero-models', 
                        model='silero_stt', 
                        language='multilingual',
                        force_reload=False,
                        trust_repo=True,
                        verbose=False
                    )
                    results.append("âœ… Ù…Ø¯Ù„ Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆÙÙ‚")
                except Exception as e:
                    results.append(f"âŒ Ù…Ø¯Ù„ Ú†Ù†Ø¯ Ø²Ø¨Ø§Ù†Ù‡: Ø®Ø·Ø§ - {str(e)}")
                
            except Exception as e:
                results.append(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ù…Ø¯Ù„: {str(e)}")
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            results_text.setPlainText("\n".join(results))
        
        # Ø¯Ú©Ù…Ù‡ ØªØ³Øª
        test_btn = QPushButton("Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª")
        test_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        test_btn.clicked.connect(run_test)
        layout.addWidget(test_btn)
        
        # Ø¯Ú©Ù…Ù‡ Ø¨Ø³ØªÙ†
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        layout.addWidget(close_btn)
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± ØªØ³Øª
        run_test()
        
        dialog.exec()
    
    def clear_silero_cache(self):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† cache Silero STT"""
        from PySide6.QtWidgets import QMessageBox
        import shutil
        
        try:
            # Ù…Ø³ÛŒØ± cache
            cache_path = Path.home() / '.cache' / 'torch' / 'hub'
            
            if cache_path.exists():
                # ØªØ£ÛŒÛŒØ¯ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±
                reply = QMessageBox.question(
                    self, "ØªØ£ÛŒÛŒØ¯ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Cache", 
                    f"Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ cache Silero STT Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯ØŸ\n\nÙ…Ø³ÛŒØ±: {cache_path}\n\nØ§ÛŒÙ† Ú©Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯.",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                
                if reply == QMessageBox.Yes:
                    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† cache
                    shutil.rmtree(cache_path)
                    QMessageBox.information(
                        self, "Ù…ÙˆÙÙ‚", 
                        "Cache Silero STT Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø§Ú© Ø´Ø¯!\n\nØ­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Silero STT Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªØ³Øª Ú©Ù†ÛŒØ¯."
                    )
                else:
                    QMessageBox.information(self, "Ù„ØºÙˆ Ø´Ø¯", "Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
            else:
                QMessageBox.information(
                    self, "Ø§Ø·Ù„Ø§Ø¹Ø§Øª", 
                    "Cache Silero STT ÛŒØ§ÙØª Ù†Ø´Ø¯.\n\nÙ…Ø³ÛŒØ±: " + str(cache_path)
                )
                
        except Exception as e:
            QMessageBox.critical(
                self, "Ø®Ø·Ø§", 
                f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† cache:\n{str(e)}\n\nÙ„Ø·ÙØ§Ù‹ Ø¯Ø³ØªÛŒ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯:\n{Path.home() / '.cache' / 'torch' / 'hub'}"
            )
    
    def download_selected_model(self, dialog):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡"""
        # ØªØ´Ø®ÛŒØµ tab ÙØ¹Ø§Ù„
        current_tab = dialog.tab_widget.currentIndex()
        
        # ØªØ¹ÛŒÛŒÙ† model_list Ùˆ model_type Ø¨Ø± Ø§Ø³Ø§Ø³ tab
        if current_tab == 0:  # Vosk tab
            model_list = dialog.vosk_list
            model_type = "Vosk"
        elif current_tab == 1:  # Whisper tab
            model_list = dialog.whisper_list
            model_type = "Whisper"
        elif current_tab == 2:  # Hugging Face tab
            model_list = dialog.hf_list
            model_type = "HuggingFace"
        elif current_tab == 3:  # SpeechRecognition tab
            model_list = dialog.sr_list
            model_type = "SpeechRecognition"
        elif current_tab == 4:  # Silero tab
            model_list = dialog.silero_list
            model_type = "Silero"
        else:
            QMessageBox.warning(dialog, "Ù‡Ø´Ø¯Ø§Ø±", "Ù„Ø·ÙØ§Ù‹ ÛŒÚ© tab Ù…Ø¹ØªØ¨Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
            return
        
        current_row = model_list.currentRow()
        if current_row == -1:
            QMessageBox.warning(dialog, "Ù‡Ø´Ø¯Ø§Ø±", "Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
            return
        
        # Ø¯Ø±ÛŒØ§ÙØª model_id
        model_ids = [key for key, value in ModelDownloader.DOWNLOADABLE_MODELS.items() 
                    if value["type"] == model_type]
        model_id = model_ids[current_row]
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø¯Ù„
        if model_type in ["SpeechRecognition"]:
            QMessageBox.information(dialog, "Ø§Ø·Ù„Ø§Ø¹Ø§Øª", f"Ù…Ø¯Ù„ {model_id} Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
            return
        
        if ModelDownloader.is_model_downloaded(model_id):
            QMessageBox.information(dialog, "Ø§Ø·Ù„Ø§Ø¹Ø§Øª", "Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
        QMessageBox.information(dialog, "Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯", f"Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_id} Ø´Ø±ÙˆØ¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")
        
        success, result = ModelDownloader.download_model(model_id)
        
        if success:
            QMessageBox.information(dialog, "Ù…ÙˆÙÙ‚", f"Ù…Ø¯Ù„ {model_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯!")
            dialog.accept()
        else:
            QMessageBox.critical(dialog, "Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {result}")
    
    def download_all_vosk_models(self, dialog):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk"""
        reply = QMessageBox.question(
            dialog, "ØªØ£ÛŒÛŒØ¯", 
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŸ\nØ§ÛŒÙ† Ú©Ø§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø²Ù…Ø§Ù† Ø²ÛŒØ§Ø¯ÛŒ Ø¨Ø¨Ø±Ø¯.",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            QMessageBox.information(dialog, "Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk Ø´Ø±ÙˆØ¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")
            
            for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
                if model_info["type"] == "Vosk" and not ModelDownloader.is_model_downloaded(model_id):
                    success, result = ModelDownloader.download_model(model_id)
                    if not success:
                        QMessageBox.critical(dialog, "Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_id}: {result}")
                        return
            
            QMessageBox.information(dialog, "Ù…ÙˆÙÙ‚", "Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯!")
            dialog.accept()
    
    def download_all_whisper_models(self, dialog):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper"""
        reply = QMessageBox.question(
            dialog, "ØªØ£ÛŒÛŒØ¯", 
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŸ\nØ§ÛŒÙ† Ú©Ø§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø²Ù…Ø§Ù† Ø²ÛŒØ§Ø¯ÛŒ Ø¨Ø¨Ø±Ø¯.",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            QMessageBox.information(dialog, "Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper Ø´Ø±ÙˆØ¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")
            
            for model_id, model_info in ModelDownloader.DOWNLOADABLE_MODELS.items():
                if model_info["type"] == "Whisper" and not ModelDownloader.is_model_downloaded(model_id):
                    success, result = ModelDownloader.download_model(model_id)
                    if not success:
                        QMessageBox.critical(dialog, "Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_id}: {result}")
                        return
            
            QMessageBox.information(dialog, "Ù…ÙˆÙÙ‚", "Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯!")
            dialog.accept()


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = VoiceApp()
    window.show()
    sys.exit(app.exec())
