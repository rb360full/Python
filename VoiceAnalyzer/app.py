import sys
import os
from pathlib import Path
from PySide6.QtWidgets import (
    QApplication, QWidget, QPushButton, QVBoxLayout, QLabel, QFileDialog,
    QTextEdit, QScrollArea, QProgressBar, QMessageBox, QDialog, QComboBox,
    QDialogButtonBox, QFormLayout
)
from PySide6.QtCore import Qt, QThread, Signal
import subprocess
import json
import collections
import webbrowser
import tempfile
import time
import requests
from tqdm import tqdm
import zipfile
import shutil

# Whisper Ùˆ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†
import whisper

# ØªØµØ­ÛŒØ­ Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ§Ø±Ø³ÛŒ
try:
    from persiantools import digits
    from persiantools import characters
    PERSIAN_TOOLS_AVAILABLE = True
except ImportError:
    PERSIAN_TOOLS_AVAILABLE = False
    print("Warning: persiantools not installed. Install with: pip install persiantools")

# Google Speech-to-Text
try:
    from google.cloud import speech
    GOOGLE_SPEECH_AVAILABLE = True
except ImportError:
    GOOGLE_SPEECH_AVAILABLE = False
    print("Warning: google-cloud-speech not installed. Install with: pip install google-cloud-speech")

# Vosk Speech Recognition
try:
    import vosk
    import json
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False
    print("Warning: vosk not installed. Install with: pip install vosk")

# Microsoft Azure Speech
try:
    import azure.cognitiveservices.speech as speechsdk
    AZURE_SPEECH_AVAILABLE = True
except ImportError:
    AZURE_SPEECH_AVAILABLE = False
    print("Warning: azure-cognitiveservices-speech not installed. Install with: pip install azure-cognitiveservices-speech")

# AssemblyAI
try:
    import assemblyai as aai
    ASSEMBLYAI_AVAILABLE = True
except ImportError:
    ASSEMBLYAI_AVAILABLE = False
    print("Warning: assemblyai not installed. Install with: pip install assemblyai")

# Ø¨Ø±Ø±Ø³ÛŒ ffmpeg Ø¯Ø± PATH
try:
    subprocess.run(["ffmpeg", "-version"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
except FileNotFoundError:
    raise RuntimeError("FFmpeg not found in PATH! Install it or add to PATH.")

# Ù…Ø³ÛŒØ± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ø³ØªÙˆÙ…
CUSTOM_DICT_FILE = Path("custom_dict.json")
if not CUSTOM_DICT_FILE.exists():
    with open(CUSTOM_DICT_FILE, "w", encoding="utf-8") as f:
        json.dump({}, f, ensure_ascii=False, indent=2)

# Ù…Ø³ÛŒØ± ØªÚ©ÛŒÙ‡ Ú©Ù„Ø§Ù…â€ŒÙ‡Ø§
RELYING_DICT_FILE = Path("relying_dict.json")
if not RELYING_DICT_FILE.exists():
    with open(RELYING_DICT_FILE, "w", encoding="utf-8") as f:
        json.dump({"ØªÚ©ÛŒÙ‡_Ú©Ù„Ø§Ù…": ["Ø®Ø¨", "Ø¢Ø®Ù‡", "ÛŒØ¹Ù†ÛŒ", "Ø­Ø§Ù„Ø§"]}, f, ensure_ascii=False, indent=2)

# Import Ù¾Ù†Ø¬Ø±Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
from custom_dict_manager import DictManager

class ModelDownloader:
    """Ú©Ù„Ø§Ø³ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
    
    # URL Ù‡Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk
    VOSK_MODELS = {
        "vosk_small": {
            "url": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
            "name": "vosk-model-small-en-us-0.15",
            "size": "40 MB",
            "language": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "warning": "âš ï¸ ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"
        },
        "vosk_large": {
            "url": "https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip", 
            "name": "vosk-model-en-us-0.22",
            "size": "1.8 GB",
            "language": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
            "warning": "âš ï¸ ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"
        },
        "vosk_persian": {
            "url": "https://alphacephei.com/vosk/models/vosk-model-fa-0.5.zip",
            "name": "vosk-model-fa-0.5", 
            "size": "1.13 GB",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "warning": "âœ… Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ"
        }
    }
    
    @staticmethod
    def download_model(model_id, progress_callback=None, progress_bar_callback=None):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Vosk"""
        if model_id not in ModelDownloader.VOSK_MODELS:
            return False, f"Ù…Ø¯Ù„ {model_id} Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯"
        
        model_info = ModelDownloader.VOSK_MODELS[model_id]
        models_dir = Path.home() / ".vosk" / "models"
        models_dir.mkdir(parents=True, exist_ok=True)
        
        model_path = models_dir / model_info["name"]
        
        # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
        if model_path.exists():
            return True, str(model_path)
        
        try:
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            if progress_callback:
                progress_callback(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_info['name']} ({model_info['size']})...")
            
            response = requests.get(model_info["url"], stream=True)
            response.raise_for_status()
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ§ÛŒÙ„
            total_size = int(response.headers.get('content-length', 0))
            downloaded_size = 0
            
            # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
            zip_path = models_dir / f"{model_info['name']}.zip"
            
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        
                        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ progress bar
                        if progress_bar_callback and total_size > 0:
                            progress_percent = int((downloaded_size / total_size) * 100)
                            progress_bar_callback(progress_percent)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„
            if progress_callback:
                progress_callback("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¯Ù„...")
            
            if progress_bar_callback:
                progress_bar_callback(100)  # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(models_dir)
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ zip
            zip_path.unlink()
            
            return True, str(model_path)
            
        except Exception as e:
            return False, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {str(e)}"
    
    @staticmethod
    def is_model_downloaded(model_id):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„"""
        if model_id not in ModelDownloader.VOSK_MODELS:
            return False
        
        model_info = ModelDownloader.VOSK_MODELS[model_id]
        models_dir = Path.home() / ".vosk" / "models"
        model_path = models_dir / model_info["name"]
        
        return model_path.exists()

class ModelSelectionDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Whisper")
        self.setModal(True)
        self.resize(400, 200)
        
        layout = QFormLayout(self)
        
        # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Whisper
        self.model_combo = QComboBox()
        models = [
            # Whisper Models
            ("whisper_tiny", "âš ï¸ Whisper Tiny - Ø®ÛŒÙ„ÛŒ Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ (75 MB)"),
            ("whisper_base", "âš ï¸ Whisper Base - Ø¶Ø¹ÛŒÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ (142 MB)"),
            ("whisper_small", "âœ… Whisper Small - ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨ (466 MB)"),
            ("whisper_medium", "âœ… Whisper Medium - Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ (1.5 GB)"),
            ("whisper_large", "âœ… Whisper Large - Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¯Ù‚Øª (2.9 GB)"),
            # Google Models
            ("google_standard", "âœ… Google Standard - Ø±Ø§ÛŒÚ¯Ø§Ù† 60Ø¯Ù‚ÛŒÙ‚Ù‡/Ù…Ø§Ù‡ (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            ("google_enhanced", "ğŸ’³ Google Enhanced - Ù¾ÙˆÙ„ÛŒØŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            ("google_phone_call", "ğŸ’³ Google Phone Call - Ù¾ÙˆÙ„ÛŒØŒ Ù…Ø®ØµÙˆØµ ØªÙ…Ø§Ø³â€ŒÙ‡Ø§ (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            ("google_medical", "ğŸ’³ Google Medical - Ù¾ÙˆÙ„ÛŒØŒ Ø§ØµØ·Ù„Ø§Ø­Ø§Øª Ù¾Ø²Ø´Ú©ÛŒ (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            ("google_video", "ğŸ’³ Google Video - Ù¾ÙˆÙ„ÛŒØŒ Ù…Ø®ØµÙˆØµ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            # Vosk Models (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù†)
            ("vosk_small", "âš ï¸ Vosk Small - ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (40 MB)"),
            ("vosk_large", "âš ï¸ Vosk Large - ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (1.8 GB)"),
            ("vosk_persian", "âœ… Vosk Persian - Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ (1.13 GB)"),
            # Microsoft Azure Speech (Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ)
            ("azure_standard", "âœ… Azure Standard - Ø±Ø§ÛŒÚ¯Ø§Ù† 5Ø³Ø§Ø¹Øª/Ù…Ø§Ù‡ (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            ("azure_enhanced", "ğŸ’³ Azure Enhanced - Ù¾ÙˆÙ„ÛŒØŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            # AssemblyAI (Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ Ø­Ø¯ÛŒ)
            ("assemblyai_standard", "âœ… AssemblyAI - Ø±Ø§ÛŒÚ¯Ø§Ù† 3Ø³Ø§Ø¹Øª/Ù…Ø§Ù‡ (Ø¢Ù†Ù„Ø§ÛŒÙ†)"),
            ("assemblyai_enhanced", "ğŸ’³ AssemblyAI Enhanced - Ù¾ÙˆÙ„ÛŒØŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± (Ø¢Ù†Ù„Ø§ÛŒÙ†)")
        ]
        
        for model_id, description in models:
            self.model_combo.addItem(f"{model_id} - {description}", model_id)
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Vosk Persian (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ - Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù†)
        self.model_combo.setCurrentIndex(10)  # vosk_persian
        
        layout.addRow("Ù…Ø¯Ù„:", self.model_combo)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addRow(buttons)
    
    def get_selected_model(self):
        return self.model_combo.currentData()

def improve_persian_text(text):
    """Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ ØªØµØ­ÛŒØ­ Ø®ÙˆØ¯Ú©Ø§Ø±"""
    if not PERSIAN_TOOLS_AVAILABLE:
        return text
    
    # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ú©Ù„Ù…Ø§Øª
    words = text.split()
    cleaned_words = []
    prev_word = None
    repeat_count = 0
    
    for word in words:
        if word == prev_word:
            repeat_count += 1
            if repeat_count < 3:  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 ØªÚ©Ø±Ø§Ø± Ù…Ø¬Ø§Ø²
                cleaned_words.append(word)
        else:
            repeat_count = 0
            cleaned_words.append(word)
        prev_word = word
    
    text = " ".join(cleaned_words)
    
    # ØªØµØ­ÛŒØ­ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
    text = characters.ar_to_fa(text)  # ØªØ¨Ø¯ÛŒÙ„ Ø¹Ø±Ø¨ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
    
    # ØªØµØ­ÛŒØ­ Ø§Ø¹Ø¯Ø§Ø¯
    text = digits.en_to_fa(text)  # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
    
    return text

class TranscribeThread(QThread):
    progress = Signal(int)
    finished = Signal(str)
    download_progress = Signal(int)
    download_status = Signal(str)

    def __init__(self, audio_path, model_name="vosk_persian"):
        super().__init__()
        self.audio_path = audio_path
        self.model_name = model_name
        self.model = None
        self._pause = False
        self._stop = False

    def run(self):
        try:
            self.progress.emit(5)
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
            if self.model_name.startswith("whisper_"):
                whisper_model = self.model_name.replace("whisper_", "")
                self.model = whisper.load_model(whisper_model)
            elif self.model_name.startswith("google_"):
                if not GOOGLE_SPEECH_AVAILABLE:
                    self.finished.emit("Error: Google Speech-to-Text not installed. Install with: pip install google-cloud-speech")
                    return
                self.model = "google"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google
            elif self.model_name.startswith("vosk_"):
                if not VOSK_AVAILABLE:
                    self.finished.emit("Error: Vosk not installed. Install with: pip install vosk")
                    return
                self.model = "vosk"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vosk
            elif self.model_name.startswith("azure_"):
                if not AZURE_SPEECH_AVAILABLE:
                    self.finished.emit("Error: Azure Speech not installed. Install with: pip install azure-cognitiveservices-speech")
                    return
                self.model = "azure"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure
            elif self.model_name.startswith("assemblyai_"):
                if not ASSEMBLYAI_AVAILABLE:
                    self.finished.emit("Error: AssemblyAI not installed. Install with: pip install assemblyai")
                    return
                self.model = "assemblyai"  # Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AssemblyAI
            else:
                self.finished.emit(f"Error: Unknown model {self.model_name}")
                return
                
            self.progress.emit(10)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ WAV 16kHz Mono Ø¯Ø± ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                temp_wav = tmp.name

            subprocess.run([
                "ffmpeg", "-y", "-i", str(self.audio_path),
                "-ar", "16000", "-ac", "1", 
                "-af", "highpass=f=80,lowpass=f=8000",  # ÙÛŒÙ„ØªØ± ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©ÛŒÙÛŒØª
                temp_wav
            ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            self.progress.emit(35)

            # ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†
            if self.model == "google":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google Speech-to-Text
                text = self.transcribe_with_google(temp_wav)
            elif self.model == "vosk":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vosk
                text = self.transcribe_with_vosk(temp_wav)
            elif self.model == "azure":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure Speech
                text = self.transcribe_with_azure(temp_wav)
            elif self.model == "assemblyai":
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AssemblyAI
                text = self.transcribe_with_assemblyai(temp_wav)
            else:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Whisper
                result = self.model.transcribe(
                    temp_wav,
                    language="fa",  # Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ
                    initial_prompt="Ø§ÛŒÙ† ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø±Ø§ Ø¨Ø§ Ø§Ù…Ù„Ø§ÛŒ ØµØ­ÛŒØ­ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯.",
                    temperature=0.0,  # Ú©Ø§Ù‡Ø´ Ø®Ù„Ø§Ù‚ÛŒØª Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
                    beam_size=5,  # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª
                    best_of=3,  # ØªØ³Øª Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø§Ø± Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡
                    patience=1.0,  # ØµØ¨Ø± Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
                    length_penalty=1.0,  # ØªÙ†Ø¸ÛŒÙ… Ø·ÙˆÙ„ Ù…ØªÙ†
                    suppress_tokens=[-1],  # Ø­Ø°Ù ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
                    word_timestamps=True,  # ØªØ´Ø®ÛŒØµ Ø¨Ù‡ØªØ± Ú©Ù„Ù…Ø§Øª
                    no_speech_threshold=0.6,  # Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ´Ø®ÛŒØµ Ø³Ú©ÙˆØª
                    logprob_threshold=-1.0,  # Ø¢Ø³ØªØ§Ù†Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ú©Ù„Ù…Ø§Øª
                    compression_ratio_threshold=2.4  # Ø¢Ø³ØªØ§Ù†Ù‡ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ
                )
                text = result["text"]
            
            # Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
            text = improve_persian_text(text)
            
            self.progress.emit(75)

            # Ù„ØºØ§Øª Ú©Ø§Ø³ØªÙˆÙ…
            with open(CUSTOM_DICT_FILE, encoding="utf-8") as f:
                custom_dict = json.load(f)
            for wrong, correct in custom_dict.items():
                text = text.replace(wrong, correct)

            # Ø¢Ù…Ø§Ø±
            words = text.split()
            word_count = len(words)

            # ØªÚ©ÛŒÙ‡ Ú©Ù„Ø§Ù…â€ŒÙ‡Ø§
            with open(RELYING_DICT_FILE, encoding="utf-8") as f:
                relying_data = json.load(f)
            relying_words = relying_data.get("ØªÚ©ÛŒÙ‡_Ú©Ù„Ø§Ù…", [])
            detected_relying = [w for w in words if w in relying_words]

            counter = collections.Counter(words)
            most_common = counter.most_common(10)

            stats = "\n\n--- Statistics ---\n"
            stats += f"Word Count: {word_count}\n"
            stats += f"Detected Pauses/Tic Words: {', '.join(detected_relying)}\n"
            stats += "Top 10 Frequent Words:\n"
            for w, c in most_common:
                stats += f"{w}: {c}\n"

            text += stats
            self.progress.emit(100)
            self.finished.emit(text)

            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            os.remove(temp_wav)

        except Exception as e:
            self.finished.emit(f"Error: {str(e)}")
    
    def transcribe_with_google(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Google Speech-to-Text"""
        try:
            client = speech.SpeechClient()
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            with open(audio_file, "rb") as audio_file_content:
                content = audio_file_content.read()
            
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ´Ø®ÛŒØµ
            audio = speech.RecognitionAudio(content=content)
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Google
            if self.model_name == "google_enhanced":
                model = "phone_call"  # Ù…Ø¯Ù„ Enhanced
            elif self.model_name == "google_phone_call":
                model = "phone_call"
            elif self.model_name == "google_medical":
                model = "medical_dictation"
            elif self.model_name == "google_video":
                model = "video"
            else:
                model = "default"  # Ù…Ø¯Ù„ Standard
            
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code="fa-IR",  # ÙØ§Ø±Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†
                model=model,
                enable_automatic_punctuation=True,
                enable_word_time_offsets=True
            )
            
            # ØªØ´Ø®ÛŒØµ
            response = client.recognize(config=config, audio=audio)
            
            # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬
            text = ""
            for result in response.results:
                text += result.alternatives[0].transcript + " "
            
            return text.strip()
            
        except Exception as e:
            error_msg = str(e)
            if "credentials" in error_msg.lower():
                return f"""Google Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… credentials

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google Speech-to-Text:

1. Ø¨Ù‡ https://console.cloud.google.com Ø¨Ø±ÙˆÛŒØ¯
2. Ù¾Ø±ÙˆÚ˜Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø³Ø§Ø²ÛŒØ¯ ÛŒØ§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯
3. API Speech-to-Text Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
4. Service Account Ø¨Ø³Ø§Ø²ÛŒØ¯ Ùˆ JSON key Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯
5. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set GOOGLE_APPLICATION_CREDENTIALS=path/to/your/key.json

ÛŒØ§ Ø§Ø² Whisper Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ø¢ÙÙ„Ø§ÛŒÙ† Ùˆ Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
            else:
                return f"Google Speech Error: {error_msg}"
    
    def transcribe_with_vosk(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Vosk"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Vosk
            if not ModelDownloader.is_model_downloaded(self.model_name):
                # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ progress bar
                def progress_callback(message):
                    self.download_status.emit(message)
                
                def progress_bar_callback(percent):
                    self.download_progress.emit(percent)
                
                success, result = ModelDownloader.download_model(
                    self.model_name, 
                    progress_callback=progress_callback,
                    progress_bar_callback=progress_bar_callback
                )
                if not success:
                    return f"Vosk Error: {result}"
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø³ÛŒØ± Ù…Ø¯Ù„
            model_path = self.get_vosk_model_path()
            if not model_path:
                return "Vosk Error: Ù…Ø¯Ù„ Vosk ÛŒØ§ÙØª Ù†Ø´Ø¯."
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
            model = vosk.Model(model_path)
            rec = vosk.KaldiRecognizer(model, 16000)
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            with open(audio_file, "rb") as f:
                data = f.read()
            
            # ØªØ´Ø®ÛŒØµ
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "")
            else:
                result = json.loads(rec.FinalResult())
                text = result.get("text", "")
            
            return text.strip()
            
        except Exception as e:
            return f"Vosk Error: {str(e)}"
    
    def get_vosk_model_path(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø³ÛŒØ± Ù…Ø¯Ù„ Vosk"""
        if self.model_name not in ModelDownloader.VOSK_MODELS:
            return None
        
        model_info = ModelDownloader.VOSK_MODELS[self.model_name]
        models_dir = Path.home() / ".vosk" / "models"
        model_path = models_dir / model_info["name"]
        
        if model_path.exists():
            return str(model_path)
        
        return None
    
    def transcribe_with_azure(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Azure Speech"""
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Azure (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)
            speech_key = os.getenv("AZURE_SPEECH_KEY")
            service_region = os.getenv("AZURE_SPEECH_REGION", "eastus")
            
            if not speech_key:
                return """Azure Speech Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Azure Speech:

1. Ø¨Ù‡ https://portal.azure.com Ø¨Ø±ÙˆÛŒØ¯
2. Cognitive Services > Speech Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯
3. API Key Ùˆ Region Ø±Ø§ Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set AZURE_SPEECH_KEY=your_key_here
   set AZURE_SPEECH_REGION=your_region_here

ÛŒØ§ Ø§Ø² Vosk Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
            
            # ØªÙ†Ø¸ÛŒÙ… speech config
            speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
            speech_config.speech_recognition_language = "fa-IR"  # ÙØ§Ø±Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†
            
            # ØªÙ†Ø¸ÛŒÙ… audio config
            audio_config = speechsdk.audio.AudioConfig(filename=audio_file)
            
            # Ø§ÛŒØ¬Ø§Ø¯ speech recognizer
            speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
            
            # ØªØ´Ø®ÛŒØµ
            result = speech_recognizer.recognize_once()
            
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                return result.text
            elif result.reason == speechsdk.ResultReason.NoMatch:
                return "Azure Speech: ØªØ´Ø®ÛŒØµ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯"
            else:
                return f"Azure Speech Error: {result.reason}"
                
        except Exception as e:
            return f"Azure Speech Error: {str(e)}"
    
    def transcribe_with_assemblyai(self, audio_file):
        """ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ AssemblyAI"""
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª AssemblyAI (Ù†ÛŒØ§Ø² Ø¨Ù‡ API Key)
            api_key = os.getenv("ASSEMBLYAI_API_KEY")
            
            if not api_key:
                return """AssemblyAI Error: Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… API Key

Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AssemblyAI:

1. Ø¨Ù‡ https://www.assemblyai.com Ø¨Ø±ÙˆÛŒØ¯
2. Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. API Key Ø±Ø§ Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯
4. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯:
   set ASSEMBLYAI_API_KEY=your_key_here

ÛŒØ§ Ø§Ø² Vosk Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù†)
"""
            
            # ØªÙ†Ø¸ÛŒÙ… API key
            aai.settings.api_key = api_key
            
            # Ø§ÛŒØ¬Ø§Ø¯ transcriber
            transcriber = aai.Transcriber()
            
            # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            transcript = transcriber.transcribe(audio_file)
            
            if transcript.status == aai.TranscriptStatus.completed:
                return transcript.text
            else:
                return f"AssemblyAI Error: {transcript.status}"
                
        except Exception as e:
            return f"AssemblyAI Error: {str(e)}"


class VoiceApp(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Voice Analyzer")
        self.resize(900, 600)  # Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ú©Ø±Ø¯Ù† Ø³Ø§ÛŒØ² Ø§Ù¾
        self.layout = QVBoxLayout(self)

        self.label = QLabel("Select an audio file:")
        self.layout.addWidget(self.label)
        
        self.model_label = QLabel("Selected Model: vosk_persian (default)")
        self.model_label.setStyleSheet("color: blue; font-weight: bold;")
        self.layout.addWidget(self.model_label)

        # Ø¯Ú©Ù…Ù‡ Ù‡Ø§
        self.btn_select = QPushButton("Choose File")
        self.btn_select.setMinimumHeight(40)
        self.btn_select.clicked.connect(self.select_file)
        self.layout.addWidget(self.btn_select)

        self.btn_start_pause = QPushButton("Start / Pause")
        self.btn_start_pause.setMinimumHeight(40)
        self.btn_start_pause.clicked.connect(self.toggle_start_pause)
        self.layout.addWidget(self.btn_start_pause)

        self.btn_stop = QPushButton("Stop")
        self.btn_stop.setMinimumHeight(40)
        self.btn_stop.clicked.connect(self.stop_processing)
        self.layout.addWidget(self.btn_stop)

        self.btn_open_text = QPushButton("Open Text")
        self.btn_open_text.setMinimumHeight(40)
        self.btn_open_text.clicked.connect(self.open_text_file)
        self.layout.addWidget(self.btn_open_text)

        self.btn_manage_dict = QPushButton("Manage Dictionary")
        self.btn_manage_dict.setMinimumHeight(40)
        self.btn_manage_dict.clicked.connect(self.open_dict_manager)
        self.layout.addWidget(self.btn_manage_dict)

        self.btn_google_setup = QPushButton("Google Setup Guide")
        self.btn_google_setup.setMinimumHeight(40)
        self.btn_google_setup.setStyleSheet("background-color: #4285f4; color: white;")
        self.btn_google_setup.clicked.connect(self.show_google_setup_guide)
        self.layout.addWidget(self.btn_google_setup)

        self.btn_download_models = QPushButton("Download Models")
        self.btn_download_models.setMinimumHeight(40)
        self.btn_download_models.setStyleSheet("background-color: #ff6b35; color: white;")
        self.btn_download_models.clicked.connect(self.show_download_models_dialog)
        self.layout.addWidget(self.btn_download_models)

        self.progress = QProgressBar()
        self.layout.addWidget(self.progress)
        
        # Progress bar Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
        self.download_progress = QProgressBar()
        self.download_progress.setVisible(False)
        self.layout.addWidget(self.download_progress)
        
        # Status label Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
        self.download_status = QLabel("")
        self.download_status.setVisible(False)
        self.download_status.setStyleSheet("color: blue; font-weight: bold;")
        self.layout.addWidget(self.download_status)

        self.scroll = QScrollArea()
        self.text_edit = QTextEdit()
        self.text_edit.setReadOnly(True)
        self.text_edit.setFontPointSize(14)  # Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø´Ø¯Ù† Ù…ØªÙ† Ù†Ù…Ø§ÛŒØ´ÛŒ
        self.scroll.setWidget(self.text_edit)
        self.scroll.setWidgetResizable(True)
        self.layout.addWidget(self.scroll)

        self.audio_path = None
        self.output_file = None
        self.thread = None
        self.dict_manager_window = None
        self.selected_model = "vosk_persian"  # Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶

    def select_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Audio File", "", 
            "Audio Files (*.mp3 *.wav *.m4a *.ogg *.flac)"
        )
        if file_path:
            self.audio_path = file_path
            self.label.setText(f"Selected: {file_path}")
            self.text_edit.clear()
            self.output_file = None
            self.thread = None  # Ø±ÛŒØ³Øª Ú©Ø±Ø¯Ù† thread Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯

    def start_transcription(self):
        if not self.audio_path:
            QMessageBox.warning(self, "Warning", "No audio file selected!")
            return

        # Ù†Ù…Ø§ÛŒØ´ dialog Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„
        dialog = ModelSelectionDialog(self)
        if dialog.exec() == QDialog.Accepted:
            self.selected_model = dialog.get_selected_model()
            self.model_label.setText(f"Selected Model: {self.selected_model}")
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ
            if self.selected_model in ["whisper_tiny", "whisper_base"]:
                reply = QMessageBox.question(
                    self, "Ù‡Ø´Ø¯Ø§Ø±", 
                    f"Ù…Ø¯Ù„ {self.selected_model} Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¶Ø¹ÛŒÙ Ø§Ø³Øª Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ØªØ§ÛŒØ¬ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¨Ø¯Ù‡Ø¯.\nØ¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Vosk
            if self.selected_model in ["vosk_small", "vosk_large"]:
                reply = QMessageBox.question(
                    self, "Ù‡Ø´Ø¯Ø§Ø± Ø²Ø¨Ø§Ù†", 
                    f"Ù…Ø¯Ù„ {self.selected_model} ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ùˆ ÙØ§Ø±Ø³ÛŒ Ø±Ø§ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯!\n\nØ¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø² 'Vosk Persian' Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\nØ¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
            paid_models = [
                "google_enhanced", "google_phone_call", "google_medical", "google_video",
                "azure_enhanced", "assemblyai_enhanced"
            ]
            if self.selected_model in paid_models:
                reply = QMessageBox.question(
                    self, "Ù‡Ø´Ø¯Ø§Ø± Ù‡Ø²ÛŒÙ†Ù‡", 
                    f"Ù…Ø¯Ù„ {self.selected_model} Ù¾ÙˆÙ„ÛŒ Ø§Ø³Øª Ùˆ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\nØ¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ØŸ",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return  # Ú©Ø§Ø±Ø¨Ø± Ø§Ù†ØµØ±Ø§Ù Ø¯Ø§Ø¯
        else:
            return  # Ú©Ø§Ø±Ø¨Ø± cancel Ú©Ø±Ø¯

        self.text_edit.clear()
        self.output_file = None
        self.thread = TranscribeThread(self.audio_path, self.selected_model)
        self.thread.progress.connect(self.progress.setValue)
        self.thread.finished.connect(self.display_result)
        self.thread.download_progress.connect(self.update_download_progress)
        self.thread.download_status.connect(self.update_download_status)
        self.thread.start()

    def update_download_progress(self, percent):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ progress bar Ø¯Ø§Ù†Ù„ÙˆØ¯"""
        self.download_progress.setValue(percent)
        if percent == 100:
            self.download_progress.setVisible(False)
            self.download_status.setVisible(False)
    
    def update_download_status(self, message):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ status Ø¯Ø§Ù†Ù„ÙˆØ¯"""
        self.download_status.setText(message)
        self.download_status.setVisible(True)
        self.download_progress.setVisible(True)

    def display_result(self, text):
        self.text_edit.setPlainText(text)
        save_path, _ = QFileDialog.getSaveFileName(
            self, "Save Text", "", "Text Files (*.txt)"
        )
        if save_path:
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(text)
            self.output_file = save_path

    def open_text_file(self):
        if self.output_file and os.path.exists(self.output_file):
            webbrowser.open(self.output_file)
        else:
            QMessageBox.warning(self, "Warning", "No saved text file to open!")

    def toggle_start_pause(self):
        if not self.audio_path:
            QMessageBox.warning(self, "Warning", "No audio file selected!")
            return

        if not self.thread:
            self.start_transcription()
        else:
            QMessageBox.information(self, "Info", "Pause / Resume toggle clicked (future implementation).")

    def stop_processing(self):
        if self.thread and self.thread.isRunning():
            QMessageBox.information(self, "Info", "Stop clicked (future implementation).")

    def open_dict_manager(self):
        if not self.dict_manager_window:
            self.dict_manager_window = DictManager()
        self.dict_manager_window.show()
        self.dict_manager_window.raise_()
        self.dict_manager_window.activateWindow()

    def show_google_setup_guide(self):
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QTextEdit, QPushButton, QHBoxLayout
        from PySide6.QtCore import Qt
        from PySide6.QtGui import QTextCursor
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Google Speech")
        dialog.setModal(True)
        dialog.resize(600, 500)
        
        layout = QVBoxLayout(dialog)
        
        # Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        text_edit.setHtml("""
        <h2>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Google Speech-to-Text</h2>
        
        <h3>ğŸ”§ Ù…Ø±Ø§Ø­Ù„ ØªÙ†Ø¸ÛŒÙ…:</h3>
        
        <h4>1ï¸âƒ£ Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡ Google Cloud:</h4>
        <p>â€¢ Ø¨Ù‡ <a href="https://console.cloud.google.com">Google Cloud Console</a> Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ Ø±ÙˆÛŒ "New Project" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ Ùˆ "Create" Ø¨Ø²Ù†ÛŒØ¯</p>
        
        <h4>2ï¸âƒ£ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ API:</h4>
        <p>â€¢ Ø¯Ø± Ù…Ù†ÙˆØŒ "APIs & Services" > "Library" Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ "Speech-to-Text API" Ø±Ø§ Ø¬Ø³ØªØ¬Ùˆ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ø±ÙˆÛŒ Ø¢Ù† Ú©Ù„ÛŒÚ© Ú©Ø±Ø¯Ù‡ Ùˆ "Enable" Ø¨Ø²Ù†ÛŒØ¯</p>
        
        <h4>3ï¸âƒ£ Ø§ÛŒØ¬Ø§Ø¯ Service Account:</h4>
        <p>â€¢ "APIs & Services" > "Credentials" Ø¨Ø±ÙˆÛŒØ¯</p>
        <p>â€¢ "Create Credentials" > "Service Account" Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Ù†Ø§Ù… Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ Role: "Cloud Speech Client" Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
        
        <h4>4ï¸âƒ£ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù„ÛŒØ¯ JSON:</h4>
        <p>â€¢ Ø±ÙˆÛŒ Service Account Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</p>
        <p>â€¢ ØªØ¨ "Keys" > "Add Key" > "Create new key"</p>
        <p>â€¢ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯</p>
        
        <h4>5ï¸âƒ£ ØªÙ†Ø¸ÛŒÙ… Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ:</h4>
        <p>â€¢ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ø§Ù…Ù† Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯</p>
        <p>â€¢ Ø¯Ø± Command Prompt Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:</p>
        <p><code>set GOOGLE_APPLICATION_CREDENTIALS=C:\\path\\to\\your\\key.json</code></p>
        
        <h3>ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:</h3>
        <p>â€¢ Google Speech 60 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ù…Ø§Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª</p>
        <p>â€¢ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨ÛŒØ´ØªØ±ØŒ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯</p>
        <p>â€¢ Whisper Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ† Ø§Ø³Øª</p>
        
        <h3>ğŸ”— Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯:</h3>
        <p>â€¢ <a href="https://console.cloud.google.com">Google Cloud Console</a></p>
        <p>â€¢ <a href="https://cloud.google.com/speech-to-text/docs">Ù…Ø³ØªÙ†Ø¯Ø§Øª Speech-to-Text</a></p>
        <p>â€¢ <a href="https://cloud.google.com/docs/authentication/external/set-up-adc">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Authentication</a></p>
        """)
        
        layout.addWidget(text_edit)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        open_console_btn = QPushButton("Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Google Cloud Console")
        open_console_btn.setStyleSheet("background-color: #4285f4; color: white; padding: 8px;")
        open_console_btn.clicked.connect(lambda: webbrowser.open("https://console.cloud.google.com"))
        
        open_docs_btn = QPushButton("Ù…Ø³ØªÙ†Ø¯Ø§Øª Speech-to-Text")
        open_docs_btn.setStyleSheet("background-color: #34a853; color: white; padding: 8px;")
        open_docs_btn.clicked.connect(lambda: webbrowser.open("https://cloud.google.com/speech-to-text/docs"))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(open_console_btn)
        button_layout.addWidget(open_docs_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    def show_download_models_dialog(self):
        """Ù†Ù…Ø§ÛŒØ´ dialog Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QListWidget, QPushButton, QHBoxLayout, QLabel
        from PySide6.QtCore import Qt
        
        dialog = QDialog(self)
        dialog.setWindowTitle("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk")
        dialog.setModal(True)
        dialog.resize(500, 400)
        
        layout = QVBoxLayout(dialog)
        
        # ØªÙˆØ¶ÛŒØ­Ø§Øª
        info_label = QLabel("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± (Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ†):")
        layout.addWidget(info_label)
        
        # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
        model_list = QListWidget()
        
        for model_id, model_info in ModelDownloader.VOSK_MODELS.items():
            status = "âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡" if ModelDownloader.is_model_downloaded(model_id) else "âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡"
            item_text = f"{model_info['name']} ({model_info['size']}) - {model_info['warning']} - {status}"
            model_list.addItem(item_text)
        
        layout.addWidget(model_list)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        button_layout = QHBoxLayout()
        
        download_btn = QPushButton("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡")
        download_btn.setStyleSheet("background-color: #4CAF50; color: white; padding: 8px;")
        download_btn.clicked.connect(lambda: self.download_selected_model(dialog, model_list))
        
        download_all_btn = QPushButton("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§")
        download_all_btn.setStyleSheet("background-color: #2196F3; color: white; padding: 8px;")
        download_all_btn.clicked.connect(lambda: self.download_all_models(dialog))
        
        close_btn = QPushButton("Ø¨Ø³ØªÙ†")
        close_btn.clicked.connect(dialog.accept)
        
        button_layout.addWidget(download_btn)
        button_layout.addWidget(download_all_btn)
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        
        dialog.exec()
    
    def download_selected_model(self, dialog, model_list):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡"""
        current_row = model_list.currentRow()
        if current_row == -1:
            QMessageBox.warning(dialog, "Ù‡Ø´Ø¯Ø§Ø±", "Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
            return
        
        model_ids = list(ModelDownloader.VOSK_MODELS.keys())
        model_id = model_ids[current_row]
        
        if ModelDownloader.is_model_downloaded(model_id):
            QMessageBox.information(dialog, "Ø§Ø·Ù„Ø§Ø¹Ø§Øª", "Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
        QMessageBox.information(dialog, "Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯", f"Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_id} Ø´Ø±ÙˆØ¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")
        
        success, result = ModelDownloader.download_model(model_id)
        
        if success:
            QMessageBox.information(dialog, "Ù…ÙˆÙÙ‚", f"Ù…Ø¯Ù„ {model_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯!")
            dialog.accept()
        else:
            QMessageBox.critical(dialog, "Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {result}")
    
    def download_all_models(self, dialog):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        reply = QMessageBox.question(
            dialog, "ØªØ£ÛŒÛŒØ¯", 
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Vosk Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŸ\nØ§ÛŒÙ† Ú©Ø§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø²Ù…Ø§Ù† Ø²ÛŒØ§Ø¯ÛŒ Ø¨Ø¨Ø±Ø¯.",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            QMessageBox.information(dialog, "Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø´Ø±ÙˆØ¹ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")
            
            for model_id in ModelDownloader.VOSK_MODELS.keys():
                if not ModelDownloader.is_model_downloaded(model_id):
                    success, result = ModelDownloader.download_model(model_id)
                    if not success:
                        QMessageBox.critical(dialog, "Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {model_id}: {result}")
                        return
            
            QMessageBox.information(dialog, "Ù…ÙˆÙÙ‚", "Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯!")
            dialog.accept()


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = VoiceApp()
    window.show()
    sys.exit(app.exec())
